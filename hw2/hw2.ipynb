{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение в анализ данных, ИАД-2\n",
    "\n",
    "## НИУ ВШЭ, 2018-19 учебный год"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание №2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание выполнил(а): _(впишите свои фамилию и имя)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Общая информация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Дата выдачи:__ 04.03.2019\n",
    "\n",
    "__Дедлайн:__ 23:59 17.03.2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценивание и штрафы\n",
    "\n",
    "Оценка за ДЗ вычисляется по следующей формуле:\n",
    "\n",
    "$$\n",
    "\\text{points} \\times 10 / 16,\n",
    "$$\n",
    "\n",
    "где points — количество обязательных баллов, которое вы набрали. Задач больше, чем необходимо сделать для получения полного балла за ДЗ. Максимальное число баллов, которое можно получить за обязательную часть — 16, а максимальное число дополнительных баллов, которые пойдут в бонус — 2.5. Бонусные задания отмечены звездочками (*).\n",
    "\n",
    "За сдачу задания позже срока на итоговую оценку за задание накладывается штраф в размере 1 балл в день, но получить отрицательную оценку нельзя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Внимание!__ Домашнее задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формат сдачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка файлов с решениями происходит в системе [Anytask](https://anytask.org/).\n",
    "\n",
    "Инвайт для группы ИАД-2: zCH4F32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN своими руками (4)\n",
    "\n",
    "Реализуйте взвешенный алгоритм kNN для регрессии. Пусть нам нужно вычислить значение $y$ для некоторого $x$ при известных данных $\\left(x_1, y_1\\right), \\ldots, \\left(x_\\ell, y_\\ell\\right)$. Предсказанием вашего регрессора будет являться\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\frac{\\sum\\limits_{i=1}^kw_iy_{(i)}}{\\sum\\limits_{i=1}^kw_i},\n",
    "$$\n",
    "где $\\left(x_{(1)}, y_{(1)}\\right), \\ldots, \\left(x_{(k)}, y_{(k)}\\right)$ - ближайшие $k$ объектов к $x$ по некоторой метрике $d(\\cdot, \\cdot)$, а $w_i = \\frac{1}{d\\left(x, x_{(i)}\\right)}$. Ваш алгоритм должен уметь работать с двумя метриками:\n",
    "\n",
    "$$\n",
    "d\\left(x_{(i)}, x\\right) = \\|x_{(i)} - x\\|_2 = \\sqrt{\\sum\\limits_{j=1}^n\\left(x_{(i)}^j - x^j\\right)^2}\\qquad\\text{(евклидова)}\n",
    "$$\n",
    "$$\n",
    "d\\left(x_{(i)}, x\\right) = \\|x_{(i)} - x\\|_1 = \\sum\\limits_{j=1}^n\\left|x_{(i)}^j - x^j\\right|\\qquad\\text{(манхэттена)}\n",
    "$$\n",
    "\n",
    "Сверьте для нескольких комбинаций различных параметров свой результат на искусственной выборке с результатом соответствующего алгоритма из `sklearn` по метрике качества MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def __init__(self, metric='euclid', k=5):\n",
    "        \"\"\"\n",
    "        PARAMETERS:\n",
    "        metric ('euclid' or 'manhattan')\n",
    "        k - number of nearest neighbors\n",
    "        \"\"\"\n",
    "        \n",
    "        self.metric = metric\n",
    "        self.k = k\n",
    "        \n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        INPUT:\n",
    "        X_train - np.array of shape (l, d)\n",
    "        y_train - np.array of shape (l,)\n",
    "        \"\"\"\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        INPUT:\n",
    "        X_test - np.array of shape (m, d)\n",
    "        \n",
    "        OUTPUT:\n",
    "        y_pred - np.array of shape (m,)\n",
    "        \"\"\"\n",
    "        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(17032019)\n",
    "X_train = np.random.randn(1000, 50)\n",
    "y_train = np.random.randn(1000,)\n",
    "X_test = np.random.randn(500, 50)\n",
    "y_test = np.random.randn(500,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия своими руками (4)\n",
    "\n",
    "Реализуйте линейную регрессию с градиентным спуском для [функции потерь Хьюбера](https://en.wikipedia.org/wiki/Huber_loss):\n",
    "\n",
    "$$\n",
    "L_\\delta\\left(y, \\hat{y}\\right) =\n",
    "\\begin{cases}\n",
    "\\frac{1}{2}\\left(y - \\hat{y}\\right)^2, \\qquad &|y - \\hat{y}| \\leq \\delta\\\\\n",
    "\\delta\\left|y - \\hat{y}\\right| - \\frac{1}{2}\\delta^2,\\qquad & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "В таком случае общее значение функции потерь на всем датасете $(x_1, y_1), \\ldots, (x_\\ell, y_\\ell)$ будет равно\n",
    "\n",
    "$$\n",
    "L = \\frac{1}{\\ell}\\sum\\limits_{i=1}^\\ell L_\\delta\\left(y_i, \\hat{y}_i\\right)\n",
    "$$\n",
    "\n",
    "Проверьте работу вашего метода: выведите результаты его работы на той же искусственной выборке, что и в задаче выше (в качестве метрик качества используйте MSE и Huber loss). Постройте график зависимости значения функции потерь от итерации градиентного спуска.\n",
    "\n",
    "*Вы можете опустить единичный признак в модели и не добавлять его в данные. Для данной искусственной выборки это не актуально, потому что целевая переменная в этом случае является случайной величиной из стандартного нормального распределения со средним 0.*\n",
    "\n",
    "*Вектор весов в градиентном спуске можете инициализировать нулями.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LinearRegressionHuber:\n",
    "    def __init__(self, delta=1.0, max_iter=1000, tol=1e-6, eta=1e-2):\n",
    "        \"\"\"\n",
    "        PARAMETERS:\n",
    "        delta - scalar in Huber loss\n",
    "        max_iter - maximum possible number of iterations in Gradient Descent\n",
    "        tol - precision for stopping criterion in Gradient Descent\n",
    "        eta - step size in Gradient Descent\n",
    "        \"\"\"\n",
    "        \n",
    "        self.delta = delta\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.eta = eta\n",
    "        \n",
    "        self.w = None\n",
    "        self.loss_history = None\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        INPUT:\n",
    "        X_train - np.array of shape (l, d)\n",
    "        y_train - np.array of shape (l,)\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.loss_history\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        INPUT:\n",
    "        X_test - np.array of shape (m, d)\n",
    "        \n",
    "        OUTPUT:\n",
    "        y_pred - np.array of shape (m,)\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "    \n",
    "    def calc_gradient(self, X, y):\n",
    "        \"\"\"\n",
    "        Calculates the gradient of Huber loss by weights.\n",
    "        \n",
    "        INPUT:\n",
    "        X - np.array of shape (l, d)\n",
    "        y - np.array of shape (l,)\n",
    "        \n",
    "        OUTPUT:\n",
    "        grad - np.array of shape (d,)\n",
    "        \"\"\"\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def calc_loss(self, X, y):\n",
    "        \"\"\"\n",
    "        Calculates the Huber loss.\n",
    "        \n",
    "        INPUT:\n",
    "        X - np.array of shape (l, d)\n",
    "        y - np.array of shape (l,)\n",
    "        \n",
    "        OUTPUT:\n",
    "        loss - float\n",
    "        \"\"\"\n",
    "        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnEAAAGDCAYAAABEP0a3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xl4nXWd///n65wkTZMm3ZKuaZtu\nFNrKGiqLS0dEQaW4MCO4MurgOMPgODiOznxxHHG+X+VyRB0Y/eG+DYg4aAVGcBxQUbawU0qhdA2l\nJd33Znv//jh36mlI2qTNyX2SvB7Xda7kvu/P/Tnv+9w59MX9uRdFBGZmZmY2uGTSLsDMzMzM+s4h\nzszMzGwQcogzMzMzG4Qc4szMzMwGIYc4MzMzs0HIIc7MzMxsEHKIMxsEJC2W1FTA/i+VdG+h+u/F\n+6+R9Pq03r87hf7MhypJuyXNSvH9Xy1pRVrvbzaQHOLMBkB3ISXt4GTDm6TJkr4haUMSvFZJ+q6k\n45Pl9ZIiWbZb0iZJt0k693D9RsSoiFiV9PFdSZ8r8HaEpDl57/+7iJhXyPc0KxYOcWbDjKSStGuw\ndEkaD/wBqABeDVQBpwK/AbqGtDERMQo4CfgVcKukSweoTv+tmh2GQ5xZkeh6RKG7oxiS/lHS5uTI\n3rvz5o+Q9EVJ65IjJl+XNDJZtlhSk6R/kLQR+E4vajlL0kOSdiQ/z8pbdmly1GaXpNWddUiaI+k3\nyTqbJf34MP2/V9JaSVsk/VOXZRlJn5T0fLL8ZknjkmWdR4cuS44gvSjpyj6u+/7kc9qc/96SRiaf\n+TZJTwOnd6lriqSfSmpOtvuKvGWfSd7r+8nnskxSQ97yaZL+K1l3i6Tr8pZ9QNLy5H3vlDTjMJ/b\nkqTv7ZLukXRC3rI1kj4u6YlkH/xYUnkPXX0M2Am8NyKej5ztEfGdiPj37laIiI0R8RXgM8AXJHX7\n70fn37Gky4B3A59IjuT9opef4y2SfihpJ3CppEWS7ku2+UVJ10kqS9r/Nln18eQ93qkuw+CSTkg+\nq+3JZ7ckb9l3JV0v6fZkvz0gaXZPn79ZsXGIMxs8JgE1wFTg/cANkjqHjb4AHAecDMxJ2ny6y7rj\ngBnAZYd7kyT03A58FRgPfAm4XdJ4SZXJ/PMjogo4C3gsWfVq4C5gLFAHdBsGJM0Hvga8F5iSvEdd\nXpMrgLcCr02WbwOu79LNnwBzgTcAn9Qfh6p7s+6rgHnAOcCn84LQPwOzk9cbyX3GnTVngF8Aj5P7\nbM8B/lbSG/P6XQLcBIwBlgLXJetmgduAtUB9sv5NybK3Av8IvB2oBX4H3NjD53Zcsuxvk7Z3AL/o\nDDSJPwPOA2YCJwKXdtcX8Hrg1ojo6GH54fwXMIHcZ9ijiLgB+BFwTTLEekEvP8cLgVvIfY4/AtrJ\nhc4a4Mxknb9K3uM1yTonJe9xyP84SCpN3u+upOa/AX6U970BuAT4F3J/tyuBf+39R2GWsojwyy+/\nCvwC1gC7ge15r73AvXltApiTN/1d4HPJ74uBNqAyb/nNwFWAgD3A7LxlZwKr89ZtAcoPU9+lnbWQ\nC1cPdll+X9KmMqn9HcDILm2+D9wA1B3hs/g0cFPedGVS3+uT6eXAOXnLJwOtQAm5EBTA8XnLrwG+\n1Yd16/KWPwhcnPy+Cjgvb9llQFPy+yuBdV2241PAd5LfPwP8T96y+cC+vH3RDJR081n8N/DBvOlM\n8ncxo5u2VwE3d2n7ArA472/sPV0+l6/3sA9WAn+ZN70k2a+7gLuSeZ2fV0mXdcuT+Wf30PfBv2Py\n/ob78Dn+9gh/P39LLoD29L1ZnLffXg1sBDJ5y28EPpNX3zfzlr0JeOZYv+9++TVQLx+JMxs4b42I\nMZ0vkqMJfbAtIvbkTa8ld7Splty5TQ8nQ0bbgV8m8zs1R8T+Xr7PlKTvfGuBqcn7vxP4S+DFZBjq\n+KTNJ8gFygeTYasPHKb/9Z0TSZ9b8pbPIHfeVee2LCd3NGZiXpv1eb93fg69XXdj3u97gVHd1dXl\nM5gBTOnsN+n7H4/Qb7ly53RNA9ZGRBsvNwP4Sl6fW8l9hlO7aXvIfoncUbT1Xdr2tG1dbSEXcDv7\nWpr8TX4MKOthnU6d77f1CO2605vPMX8fIOk45S6o2JgMsf5fckflemMKsD4OPeK4lqP7zMyKjkOc\nWfHYSy6MdZrUZfnYZDiz03RgA7AZ2AcsyAuJoyN3Mnqn6EMdG8j9Y5tvOrmjPkTEnRFxLrkQ8Azw\njWT+xoj4i4iYAnwY+A/lneOX50VywQYASRXkhlQ7rSc3XDsm71UeES/ktZmW93vn59DbdXtySF1J\nv/k1re7Sb1VEvKkX/a4Hpqv7k/TXAx/u0u/IiPhDN20P2S+SlNTbm23r6tfAW3s6r+0I3ga8BPTm\nNh5d/+568zl2Xedr5P7O5kZENbnQp17WugGY1mU7D/4tmw12DnFmxeMx4F2SspLOI3deV1f/IqlM\n0quBtwA/SY4yfAO4VtIEAElTu5xn1Bd3AMdJepekEknvJDc8eJukicnJ9ZXAAXJDxO3Je/6ppM5z\n27aR+8e4vZv+bwHeIulVyflcn+XQ/xZ9HfjXzhP8JdVKurBLH1dJqpC0APhz4Md9WLcnNwOfkjQ2\n2Y6/yVv2ILBTuYtDRib7aKGk07vv6hAPkguIn5dUKalc0tl59X4q2Q4kjZb0p4ep782SzknO9bqS\n3D7oLvAdyZfInQP2A0mzlVNF7pzKbiX7/nJy5w5+Knp3Pt0mIP+ecUfzOVaRuwhjd3LU9yNHeI98\nD5A71eATkkolLQYuIDkn0Wywc4gzKx4fJfcPzHZyV/X9rMvyjeTC0QZyJ3z/ZUQ8kyz7B3LnOd2f\nDDn9D0c48bwnEbGFXEC8ktyw2yeAt0TEZnL/zbgyqWEruaDZOSx8OvCApN3kTuz/aESs7qb/ZcBf\nA/9JLtxsA/JvqvuVZP27JO0C7id3LlW+3yTb+2vgixFxVx/W7cm/kBtqW03uRPgf5NXcTm7fnJws\n3wx8Exh9pE7z1p0DrEu29Z3JslvJXZRyU7LfngLO76GfFcB7yF0wsjnp84KIaOnl9uX3tRk4A9gP\n3EvuXLjHyAWmriFpu6Q9wJPkzhn704j4di/f6lvA/GTo9GdH+Tl+HHhXUuM3+GNg7/QZ4HvJe/xZ\nl+1sIXe+3/nJe/0H8L68743ZoKaIvoyymJmlR1I9uX/8S3s4x8zMbNjwkTgzMzOzQcghzszMzGwQ\n8nCqmZmZ2SDkI3FmZmZmg5BDnJmZmdkg1N3NJ4ecmpqaqK+vT7sMMzMzsyN6+OGHN0dE7ZHaDYsQ\nV19fT2NjY9plmJmZmR2RpK6PPuyWh1PNzMzMBqGChjhJ50laIWmlpE8ept1FkkJSQzJ9rqSHJT2Z\n/HxdN+sslfRUIes3MzMzK1YFG06VlAWuB84l95iZhyQtjYinu7SrAq4g94y7TpvJPU5mg6SFwJ3A\n1Lx13k7umY1mZmZmw1Ihj8QtAlZGxKrk+XU3Ad09iPpq4Bpyz/ADICIejYgNyeQyoFzSCABJo4C/\nAz5XwNrNzMzMilohQ9xUYH3edBN5R9MAJJ0CTIuI2w7TzzuARyPiQDJ9NfBvwN7DvbmkyyQ1Smps\nbm7uc/FmZmZmxayQIU7dzDv4eAhJGeBa4MoeO5AWAF8APpxMnwzMiYhbj/TmEXFDRDRERENt7RGv\n0jUzMzMbVAoZ4pqAaXnTdcCGvOkqYCFwj6Q1wBnA0ryLG+qAW4H3RcTzyTpnAqcl7e8FjpN0TwG3\nwczMzKwoFTLEPQTMlTRTUhlwMbC0c2FE7IiImoioj4h64H5gSUQ0ShoD3A58KiJ+n7fO1yJiStL+\nVcCzEbG4gNtgZmZmVpQKFuIiog24nNyVpcuBmyNimaTPSlpyhNUvB+YAV0l6LHlNKFStZmZmZoON\nIuLIrQa5hoaG8BMbzMzMbDCQ9HBENBypnZ/YYGZmZjYIOcT1g+Uv7uT+VVvSLsPMzMyGEYe4fvBv\ndz3LP/98WdplmJmZ2TDiENcP6sdXsHbrHobD+YVmZmZWHBzi+sGM8RXsb+3gpV0HjtzYzMzMrB84\nxPWD6eMrAVi75bBPAjMzMzPrNw5x/aB+fAUAa7bsSbkSMzMzGy4c4vrBlDEjyWbEOh+JMzMzswHi\nENcPSrMZ6saO9JE4MzMzGzAOcf1k+rgK1m31kTgzMzMbGA5x/aR+fKUvbDAzM7MB4xDXT2aMr2DH\nvla2721JuxQzMzMbBhzi+sn0cbkrVH00zszMzAaCQ1w/qa/J3SvOFzeYmZnZQHCI6yedR+J8mxEz\nMzMbCA5x/aS8NMuk6nLWOMSZmZnZAHCI60fTx1ewbquHU83MzKzwHOL6Uf34Ch+JMzMzswHhENeP\nZoyvpHnXAfa2tKVdipmZmQ1xDnH9aMZ432bEzMzMBoZDXD+aMS53mxGHODMzMys0h7h+ND05EueL\nG8zMzKzQHOL60eiRpYytKPXFDWZmZlZwDnH9bPr4St/w18zMzArOIa6f1Y+vYPVmD6eamZlZYTnE\n9bOZNZVs2LGP/a3taZdiZmZmQ5hDXD+bVTuKCF+hamZmZoXlENfPZtXkbjOyqnl3ypWYmZnZUOYQ\n189mdoY4nxdnZmZmBVTQECfpPEkrJK2U9MnDtLtIUkhqSKbPlfSwpCeTn69L5ldIul3SM5KWSfp8\nIes/GpUjSphYPYJVzQ5xZmZmVjgFC3GSssD1wPnAfOASSfO7aVcFXAE8kDd7M3BBRLwCeD/wg7xl\nX4yI44FTgLMlnV+gTThqs2pGsXqzh1PNzMyscAp5JG4RsDIiVkVEC3ATcGE37a4GrgH2d86IiEcj\nYkMyuQwolzQiIvZGxN1JmxbgEaCugNtwVGbWVno41czMzAqqkCFuKrA+b7opmXeQpFOAaRFx22H6\neQfwaEQc6LLuGOAC4NfdrSTpMkmNkhqbm5uPpv6jNqumku17W9m2p2VA39fMzMyGj0KGOHUzLw4u\nlDLAtcCVPXYgLQC+AHy4y/wS4EbgqxGxqrt1I+KGiGiIiIba2tqjKP/ozartvLjBQ6pmZmZWGIUM\ncU3AtLzpOmBD3nQVsBC4R9Ia4Axgad7FDXXArcD7IuL5Ln3fADwXEV8uUO3HZFbNKABf3GBmZmYF\nU1LAvh8C5kqaCbwAXAy8q3NhROwAajqnJd0DfDwiGpOh0tuBT0XE7/M7lfQ5YDTwoQLWfkzqxo6k\nNCufF2dmZmYFU7AjcRHRBlwO3AksB26OiGWSPitpyRFWvxyYA1wl6bHkNSE5OvdP5K52fSSZX3Rh\nriSbYfq4Clb7SJyZmZkVSCGPxBERdwB3dJn36R7aLs77/XPA53rotrtz7YrOzJpRPifOzMzMCsZP\nbCiQ2bWVrNmyl/aOOHJjMzMzsz5yiCuQmTWVtLR1sGH7vrRLMTMzsyHIIa5AZtUmV6j64gYzMzMr\nAIe4AplZk9wrrtnnxZmZmVn/c4grkJpRZVSVl7DaR+LMzMysABziCkQSs2oqfcNfMzMzKwiHuAKa\nVTvKw6lmZmZWEA5xBTRnwig27NjPngNtaZdiZmZmQ4xDXAHNTq5Qfd5H48zMzKyfOcQV0NyJuRD3\n3CaHODMzM+tfDnEFNGNcBaVZ8dxLDnFmZmbWvxziCqgkm2FWzShWvrQr7VLMzMxsiHGIK7A5E0ax\n0kfizMzMrJ85xBXYnAmjWLd1L/tb29MuxczMzIYQh7gCmztxFB2Bb/prZmZm/cohrsDmTqgC4Dmf\nF2dmZmb9yCGuwOprKshmxPM+L87MzMz6kUNcgY0oyTJjXIVvM2JmZmb9yiFuAMyZMMohzszMzPqV\nQ9wAmDtxFGs276G1vSPtUszMzGyIcIgbAHMnVNHWEazd4itUzczMrH84xA2AORP8DFUzMzPrXw5x\nA2B27SgkfF6cmZmZ9RuHuAEwsixL3diRDnFmZmbWbxziBsjcCVV+hqqZmZn1G4e4ATJ3wiieb95N\nm69QNTMzs37gEDdA5k2qoqWtgzW+QtXMzMz6gUPcAJk3KfcM1Wc2+hmqZmZmduwc4gbInAmjyGbE\nCoc4MzMz6wcFDXGSzpO0QtJKSZ88TLuLJIWkhmT6XEkPS3oy+fm6vLanJfNXSvqqJBVyG/rLiJIs\ns2oqWf6iQ5yZmZkdu4KFOElZ4HrgfGA+cImk+d20qwKuAB7Im70ZuCAiXgG8H/hB3rKvAZcBc5PX\neQXZgAKYN6mKFZt2pl2GmZmZDQGFPBK3CFgZEasiogW4Cbiwm3ZXA9cA+ztnRMSjEbEhmVwGlEsa\nIWkyUB0R90VEAN8H3lrAbehXx0+qYv3Wfew+0JZ2KWZmZjbIFTLETQXW5003JfMOknQKMC0ibjtM\nP+8AHo2IA8n6TYfrs5jNm1QN4PPizMzM7JgVMsR1d65aHFwoZYBrgSt77EBaAHwB+HBv+uyy7mWS\nGiU1Njc397roQjo+uULVIc7MzMyOVSFDXBMwLW+6DtiQN10FLATukbQGOANYmndxQx1wK/C+iHg+\nr8+6w/R5UETcEBENEdFQW1vbD5tz7OrGjmTUiBJWbPR5cWZmZnZsChniHgLmSpopqQy4GFjauTAi\ndkRETUTUR0Q9cD+wJCIaJY0Bbgc+FRG/z1vnRWCXpDOSq1LfB/y8gNvQryRx3MRRLPeRODMzMztG\nBQtxEdEGXA7cCSwHbo6IZZI+K2nJEVa/HJgDXCXpseQ1IVn2EeCbwErgeeC/C7MFhTFvUjUrNu4i\nd12GmZmZ2dEpKWTnEXEHcEeXeZ/uoe3ivN8/B3yuh3aN5IZhB6UTJldx44Pr2LTzAJNGl6ddjpmZ\nmQ1SfmLDAJs3MXdxw3KfF2dmZmbHwCFugB3v24yYmZlZP3CIG2CjK0qZPLrcIc7MzMyOiUNcCuZN\nqmL5ix5ONTMzs6PnEJeCeZOqeL55Ny1tHWmXYmZmZoOUQ1wKFkwZTWt78NxLHlI1MzOzo+MQl4IF\nU3IXNyzb4CFVMzMzOzoOcSmYOb6SirIsTzvEmZmZ2VFyiEtBJiNOmFzNsg070i7FzMzMBimHuJQs\nmFLN0xt20tHhx2+ZmZlZ3znEpWTBlGr2tLSzduvetEsxMzOzQcghLiULpowG8JCqmZmZHRWHuJQc\nN7GK0qx46gVf3GBmZmZ95xCXkrKSDHMnVPlInJmZmR0Vh7gUdV7cEOGLG8zMzKxvHOJStGBKNVv2\ntLBp54G0SzEzM7NBxiEuRQum+uIGMzMzOzoOcSk6YXI1kh+/ZWZmZn3nEJeiUSNKmDm+0kfizMzM\nrM8c4lI2f0q1j8SZmZlZnznEpWzh1NE0bdvHtj0taZdiZmZmg4hDXMpOTC5ueOIFD6mamZlZ7znE\npWxh3WgkeGL99rRLMTMzs0HEIS5l1eWlzKqp5PEmhzgzMzPrPYe4InBS3Rgeb9rhJzeYmZlZrznE\nFYGTpo2hedcBNu7cn3YpZmZmNkg4xBWBE+tyFzc87vPizMzMrJcc4orACZOrKcmIx5t8haqZmZn1\njkNcESgvzXLC5Gqe8MUNZmZm1ksFDXGSzpO0QtJKSZ88TLuLJIWkhmR6vKS7Je2WdF2XtpdIelLS\nE5J+KammkNswUE6sG80TTTvo6PDFDWZmZnZkBQtxkrLA9cD5wHzgEknzu2lXBVwBPJA3ez9wFfDx\nLm1LgK8AfxIRJwJPAJcXZAMG2El1Y9i1v43VW/akXYqZmZkNAoU8ErcIWBkRqyKiBbgJuLCbdlcD\n15ALbgBExJ6IuDd/XkLJq1KSgGpgQyGKH2gnTkue3OAhVTMzM+uFQoa4qcD6vOmmZN5Bkk4BpkXE\nbb3pMCJagY8AT5ILb/OBb/VLtSmbO6GKirIsj6/3xQ1mZmZ2ZIUMcepm3sETviRlgGuBK3vdoVRK\nLsSdAkwhN5z6qR7aXiapUVJjc3NzX+pORTYjFk4Z7Sc3mJmZWa8UMsQ1AdPypus4dOizClgI3CNp\nDXAGsLTz4oYenAwQEc9H7vEGNwNnddcwIm6IiIaIaKitrT36rRhAJ9aNZtmGnbS2d6RdipmZmRW5\nQoa4h4C5kmZKKgMuBpZ2LoyIHRFRExH1EVEP3A8siYjGw/T5AjBfUmcqOxdYXpjyB97J08fQ0tbB\n8hd3pl2KmZmZFbmSQnUcEW2SLgfuBLLAtyNimaTPAo0RsfRw6ydH56qBMklvBd4QEU9L+hfgt5Ja\ngbXApYXahoF22oyxADy8dhsn1o1JuRozMzMrZgULcQARcQdwR5d5n+6h7eIu0/U9tPs68PX+qbC4\nTB49kimjy3lk3Xb+/Oy0qzEzM7Ni5ic2FJlTZ4zlkbXb0i7DzMzMipxDXJE5dfpYXti+jxd37Eu7\nFDMzMytiDnFFpvO8uEfW+lYjZmZm1jOHuCIzf0o15aUZHlnnIVUzMzPrmUNckSnNZjixbgwP+7w4\nMzMzOwyHuCJ06vSxLNuwg/2t7WmXYmZmZkXKIa4InTZjLK3twVMv+DmqZmZm1j2HuCJ06vTcjX49\npGpmZmY9cYgrQuNHjWBmTaVDnJmZmfXIIa5InTJ9DI+s205EpF2KmZmZFSGHuCJ12oyxbN59gLVb\n9qZdipmZmRUhh7gi9cqZ4wB4cPXWlCsxMzOzYuQQV6Rm145ifGUZDzjEmZmZWTcc4oqUJBbNHMcD\nq7ekXYqZmZkVIYe4IrZo5jiatu3jhe370i7FzMzMioxDXBF75czxADzoo3FmZmbWhUNcEZs3qYrq\n8hJf3GBmZmYv4xBXxLKZ5Ly4VQ5xZmZmdiiHuCK3aOY4Vm3ew0u79qddipmZmRURh7gi98fz4nw0\nzszMzP7IIa7ILZhSTWVZ1kOqZmZmdgiHuCJXks1wWv04H4kzMzOzQzjEDQKvnDmOFZt2sXVPS9ql\nmJmZWZFwiBsEzpiVOy/u/lW+X5yZmZnlOMQNAifVjWbUiBJ+v3Jz2qWYmZlZkXCIGwRKshnOmDXO\nIc7MzMwOcogbJM6eU8OaLXtp2rY37VLMzMysCDjEDRJnz6kB4A8rfV6cmZmZ9TLESZotaUTy+2JJ\nV0gaU9jSLN/cCaOorRrBvR5SNTMzM3p/JO6nQLukOcC3gJnAfxasKnsZSbxqTg2/X7mZjo5Iuxwz\nMzNLWW9DXEdEtAFvA74cER8DJh9pJUnnSVohaaWkTx6m3UWSQlJDMj1e0t2Sdku6rkvbMkk3SHpW\n0jOS3tHLbRj0zpo9ni17WlixaVfapZiZmVnKSnrZrlXSJcD7gQuSeaWHW0FSFrgeOBdoAh6StDQi\nnu7Srgq4Anggb/Z+4CpgYfLK90/ASxFxnKQMMK6X2zDodZ4X9/uVmzlhcnXK1ZiZmVmaensk7s+B\nM4F/jYjVkmYCPzzCOouAlRGxKiJagJuAC7tpdzVwDbngBkBE7ImIe/Pn5fkA8P+Sdh0RMWxOEpsy\nZiSzait9qxEzMzPrXYiLiKcj4oqIuFHSWKAqIj5/hNWmAuvzppuSeQdJOgWYFhG39aaOvIsprpb0\niKSfSJrYQ9vLJDVKamxubu5N94PC2bNreGD1VlraOtIuxczMzFLU26tT75FULWkc8DjwHUlfOtJq\n3cw7eEZ+MhR6LXBlb4slN/xbB/w+Ik4F7gO+2F3DiLghIhoioqG2trYPb1Hczp5Tw96Wdh5dty3t\nUszMzCxFvR1OHR0RO4G3A9+JiNOA1x9hnSZgWt50HbAhb7qK3Plu90haA5wBLO28uKEHW4C9wK3J\n9E+AU3u5DUPC2XPGU5IR9zw7dI4umpmZWd/1NsSVSJoM/BnQq6FP4CFgrqSZksqAi4GlnQsjYkdE\n1EREfUTUA/cDSyKisacOIyKAXwCLk1nnAE/31H4oqiov5bQZY7lnhUOcmZnZcNbbEPdZ4E7g+Yh4\nSNIs4LnDrZDckuTyZL3lwM0RsUzSZyUtOdIbJkfnvgRcKqlJ0vxk0T8An5H0BPBe+jYcOyQsnjeB\n5S/uZOOO7q77MDMzs+FAuYNbQ1tDQ0M0NvZ4gG/QeWbjTs778u/4wjtewTtPn552OWZmZtaPJD0c\nEYc7vQzo/YUNdZJulfSSpE2Sfiqp7tjLtKMxb2IVk6rLPaRqZmY2jPV2OPU75M5nm0LuNiG/SOZZ\nCiSxeF4t9z63mdZ232rEzMxsOOptiKuNiO9ERFvy+i4wdO7bMQgtnlfLrgNtPLzWtxoxMzMbjnob\n4jZLeo+kbPJ6D7nbfVhKzp5Tk7vViIdUzczMhqXehrgPkLu9yEbgReAico/ispRUlZfSUD+We1a8\nlHYpZmZmloLePnZrXUQsiYjaiJgQEW8ld+NfS9HieRN4ZuMuXtyxL+1SzMzMbID19khcd/6u36qw\no/K64ycA8L/P+GicmZnZcHMsIa67Z6PaAJo7YRQzxldw17JNaZdiZmZmA+xYQtzQv0twkZPEuSdM\n5L7nt7D7QFva5ZiZmdkAOmyIk7RL0s5uXrvI3TPOUnbu/Im0tHfwG1+lamZmNqwcNsRFRFVEVHfz\nqoqIkoEq0np22oyxjKss466nN6ZdipmZmQ2gYxlOtSJQks3wuuMncPczL/npDWZmZsOIQ9wQcO78\niezc38aDq7emXYqZmZkNEIe4IeDVc2sYUZLhV0/7KlUzM7PhwiFuCKgoK+HVc2u5a9lGInzRsJmZ\n2XDgEDdEvGH+RDbs2M+yDTvTLsXMzMwGgEPcEHHOCRPIZsR/P/Vi2qWYmZnZAHCIGyLGjxrBmbPG\nc/sTL3pI1czMbBhwiBtC3nziZNZs2eshVTMzs2HAIW4IeeOCSWQz4vYnPaRqZmY21DnEDSHjKss4\na/Z47njSQ6pmZmZDnUPcEPOWEyez1kOqZmZmQ55D3BDzhvm5IdXbnvCQqpmZ2VDmEDfEjK0s4+w5\nNdz+5AYPqZqZmQ1hDnFD0FteMZn1W/fx5As70i7FzMzMCsQhbgh644JJlGUz/PyxDWmXYmZmZgXi\nEDcEja4o5U+Or+Xnj22grb0j7XLMzMysABzihqi3nTKVzbsP8Pvnt6RdipmZmRWAQ9wQ9SfHT2D0\nyFJufaQp7VLMzMysAAoa4iSdJ2mFpJWSPnmYdhdJCkkNyfR4SXdL2i3puh7WWSrpqULVPtiNKMny\n5hMnc+eyTew50JZ2OWZmZtbN05rtAAAe2ElEQVTPChbiJGWB64HzgfnAJZLmd9OuCrgCeCBv9n7g\nKuDjPfT9dmB3f9c81LztlKnsa23nzmUb0y7FzMzM+lkhj8QtAlZGxKqIaAFuAi7spt3VwDXkghsA\nEbEnIu7Nn9dJ0ijg74DPFaTqIaRhxlimjRvJrY++kHYpZmZm1s8KGeKmAuvzppuSeQdJOgWYFhG3\n9aHfq4F/A/YerpGkyyQ1Smpsbm7uQ/dDhyTedvJUfr9yM5t2viwPm5mZ2SBWyBCnbuYdfISApAxw\nLXBlrzuUTgbmRMStR2obETdERENENNTW1vb2LYact54ylY7AR+PMzMyGmEKGuCZgWt50HZB/99kq\nYCFwj6Q1wBnA0s6LG3pwJnBa0v5e4DhJ9/RjzUPOrNpRnF4/lpsfWu/HcJmZmQ0hhQxxDwFzJc2U\nVAZcDCztXBgROyKiJiLqI6IeuB9YEhGNPXUYEV+LiClJ+1cBz0bE4gJuw5DwztOns2rzHh5asy3t\nUszMzKyfFCzERUQbcDlwJ7AcuDkilkn6rKQlR1o/Odr2JeBSSU3dXdlqvfOmV0yiakQJNz20Lu1S\nzMzMrJ+UFLLziLgDuKPLvE/30HZxl+n6I/S9htxwrB1BRVkJS06ewk8faeKfL1jA6JGlaZdkZmZm\nx8hPbBgmLj59OvtbO1j6mC9wMDMzGwoc4oaJhVOrmT+5mpseWn/kxmZmZlb0HOKGCUlcvGgayzbs\n5MmmHWmXY2ZmZsfIIW4YufDkqZSXZvjPB9emXYqZmZkdI4e4YWT0yFLeevJUbn30BXbsbU27HDMz\nMzsGDnHDzHvPnMH+1g5+8rDPjTMzMxvMHOKGmQVTRnN6/Vi+f99aOjr8BAczM7PByiFuGHrfmfWs\n27qX3zzbnHYpZmZmdpQc4oahNy6YxISqEXzvvjVpl2JmZmZHySFuGCoryfCuV07nnhXNrNm8J+1y\nzMzM7Cg4xA1T71o0ndKs+O4f1qRdipmZmR0Fh7hhakJ1OUtOmsqPH1rP9r0taZdjZmZmfeQQN4z9\nxWtmsq+1nR/e75v/mpmZDTYOccPY8ZOqec1xtXz3D2vZ39qedjlmZmbWBw5xw9yHXzOLzbsP8LNH\nX0i7FDMzM+sDh7hh7qzZ45k/uZobfrfKN/81MzMbRBzihjlJfPi1s1jVvIdfP/NS2uWYmZlZLznE\nGW96xWSmjhnJ9XevJMJH48zMzAYDhzijNJvhr/5kNo+t387vntucdjlmZmbWCw5xBsBFp9UxeXQ5\nX/31cz4aZ2ZmNgg4xBkAI0qy/OVrZ9O4dhv3rdqSdjlmZmZ2BA5xdtA7T5/GhKoR/PuvV6ZdipmZ\nmR2BQ5wdVF6a5cOvnc19q7bw4OqtaZdjZmZmh+EQZ4d416Lp1IwawZd+tcLnxpmZmRUxhzg7xMiy\nLH/zujncv2qrr1Q1MzMrYg5x9jKXLJpO3diRXHPnM36Kg5mZWZFyiLOXKSvJ8HfnHsdTL+zkjqde\nTLscMzMz64ZDnHXrwpOnctzEUfzbXc/S2t6RdjlmZmbWhUOcdSubEX//xuNZvXkPP2lsSrscMzMz\n66KgIU7SeZJWSFop6ZOHaXeRpJDUkEyPl3S3pN2SrstrVyHpdknPSFom6fOFrH+4e/0JEzhtxli+\n9Ktn2bW/Ne1yzMzMLE/BQpykLHA9cD4wH7hE0vxu2lUBVwAP5M3eD1wFfLybrr8YEccDpwBnSzq/\nv2u3HElc9Zb5bN59gP+45/m0yzEzM7M8hTwStwhYGRGrIqIFuAm4sJt2VwPXkAtuAETEnoi4N39e\nMn9vRNyd/N4CPALUFah+A06eNoa3nzKVb/1uNeu37k27HDMzM0sUMsRNBdbnTTcl8w6SdAowLSJu\n62vnksYAFwC/PpYi7cg+cd7xZDPi//338rRLMTMzs0QhQ5y6mXfwpmOSMsC1wJV97lgqAW4EvhoR\nq3poc5mkRkmNzc3NfX0LyzNpdDkfWTybO57cyP2rtqRdjpmZmVHYENcETMubrgM25E1XAQuBeySt\nAc4AlnZe3HAENwDPRcSXe2oQETdERENENNTW1va5eDvUX7x6FlNGl/OZpct8yxEzM7MiUMgQ9xAw\nV9JMSWXAxcDSzoURsSMiaiKiPiLqgfuBJRHReLhOJX0OGA38beFKt65GlmX59AULeGbjLr7z+9Vp\nl2NmZjbsFSzERUQbcDlwJ7AcuDkilkn6rKQlR1o/OTr3JeBSSU2S5kuqA/6J3NWuj0h6TNKHCrUN\ndqg3LpjI60+YwLW/eo4Xtu9LuxwzM7NhTRFD/9mYDQ0N0dh42AN81ktN2/Zy7pd+y6vm1vCN9/Vm\n5NvMzMz6QtLDEXHEf2T9xAbrk7qxFXz09XP51dObuGvZxrTLMTMzG7Yc4qzPPviqmcybWMVnli5j\n94G2tMsxMzMblhzirM9Ksxn+79sX8uLO/Xze944zMzNLhUOcHZXTZozjA2fP5If3r+Pe5zanXY6Z\nmdmw4xBnR+3v3ziPWbWVfOKWx9m1vzXtcszMzIYVhzg7auWlWb74pyexced+Pnebh1XNzMwGkkOc\nHZNTp4/lstfM5seN67n7mZfSLsfMzGzYcIizY/axc+dy3MRRfOKnT7B594G0yzEzMxsWHOLsmI0o\nyfLVS05hx75Wrrz5cTo6hv4NpM3MzNLmEGf94vhJ1Xz6LfP5zbPNfPPeVWmXY2ZmNuQ5xFm/efcr\np3P+wklc88sVPLZ+e9rlmJmZDWkOcdZvJPH5t5/IxOpyrrjxUXb6tiNmZmYF4xBn/Wp0RSlfveRk\nNmzfx9/9+DGfH2dmZlYgDnHW706bMY6r3jKf/1n+El/93+fSLsfMzGxIcoizgnjfmTN4x6l1fPl/\nnuNXT29KuxwzM7MhxyHOCkIS//q2hZxYN5qP/fgxVr60O+2SzMzMhhSHOCuY8tIsX3/PaYwoyXDZ\n9xvZvrcl7ZLMzMyGDIc4K6gpY0by9feeRtO2fVz2g4c50NaedklmZmZDgkOcFdzp9eP44p+dxIOr\nt/L3P3nCV6yamZn1g5K0C7DhYclJU2jatpdrfrmCaeNG8vdvPD7tkszMzAY1hzgbMB957WzWb93H\n9Xc/z6Tqct57Zn3aJZmZmQ1aDnE2YCRx9YULaN61n6t+vozKESW8/dS6tMsyMzMblHxOnA2okmyG\n6951KmfNHs/f3/IEv3xqY9olmZmZDUoOcTbgykuzfON9DZxYN5orbnyU3z7bnHZJZmZmg45DnKWi\nckQJ3710EbMnjOKyHzTyu+cc5MzMzPrCIc5SM7qilB9+cBH14yv54PcaufuZl9IuyczMbNBwiLNU\njR81ghv/4gyOm5g7InfXMp8jZ2Zm1hsOcZa6sZVl/OhDZ7Bgymj+6keP8PPHXki7JDMzs6LnEGdF\nYfTIUn7wwUWcOmMsH73pMb75u1Vpl2RmZlbUChriJJ0naYWklZI+eZh2F0kKSQ3J9HhJd0vaLem6\nLm1Pk/Rk0udXJamQ22ADp6q8lO9/YBHnL5zE525fztW3Pe1HdJmZmfWgYCFOUha4HjgfmA9cIml+\nN+2qgCuAB/Jm7weuAj7eTddfAy4D5iav8/q3cktTeWmW6951KpeeVc+37l3NFTc9yoG29rTLMjMz\nKzqFPBK3CFgZEasiogW4Cbiwm3ZXA9eQC24ARMSeiLg3fx6ApMlAdUTcFxEBfB94a6E2wNKRzYh/\nvmA+nzr/eG574kXe/Y0HaN51IO2yzMzMikohQ9xUYH3edFMy7yBJpwDTIuK2PvTZdLg+bWiQxIdf\nO5t/v+QUntqwgyXX3cuTTTvSLsvMzKxoFDLEdXeu2sETnCRlgGuBK/urz0MaSpdJapTU2NzsG8kO\nVhecNIVb/vIsMhIXff0PvnLVzMwsUcgQ1wRMy5uuAzbkTVcBC4F7JK0BzgCWdl7ccJg+85+Y3rXP\ngyLihohoiIiG2traoyjfisXCqaNZevnZnDRtDB+96TGuvu1pWto60i7LzMwsVYUMcQ8BcyXNlFQG\nXAws7VwYETsioiYi6iOiHrgfWBIRjT11GBEvArsknZFclfo+4OcF3AYrEuNHjeBHH3rlwQse/vTr\nf2Ddlr1pl2VmZpaagoW4iGgDLgfuBJYDN0fEMkmflbTkSOsnR+e+BFwqqSnvytaPAN8EVgLPA/9d\niPqt+JRmM3xmyQK+/p7TWL15D2/+6u/4xePdHog1MzMb8pS7yHNoa2hoiMbGHg/w2SDUtG0vf3Pj\nozy6bjt/1lDHVW+ZT1V5adplmZmZHTNJD0fE4U4vA/zEBhuk6sZWcPOHz+SvFs/mloebeOO1v+Xe\n5zanXZaZmdmAcYizQas0m+ET5x3PLR85i/KyLO/51gP8n589yZ4DbWmXZmZmVnAOcTbonTp9LHdc\n8Wo+9KqZ/OiBdbzh2t9y57KNDIdTBczMbPhyiLMhobw0y/95y3xu+cszGTWihA//4GE+9L1G1m/1\nFaxmZjY0OcTZkHLajHHcdsWr+Kc3ncB9q7bw+i/9huv+9zn2t/r5q2ZmNrQ4xNmQU5rN8BevmcWv\nr3wt55wwgS/e9Szn/Ntv+NmjL9DR4SFWMzMbGhzibMiaPHok//Hu0/jPD72SMRWl/O2PH2PJ9ffy\nh5W+itXMzAY/hzgb8s6aU8MvLn8V177zJLbtaeVd33yA93/7QR5dty3t0szMzI6ab/Zrw8r+1na+\n+4c1/H+/eZ5te1t57XG1fPT1czl1+ti0SzMzMwN6f7NfhzgblnYfaOMH963lG79bxdY9Lbx6bg1/\ntXgOZ8waR+6xvGZmZulwiMvjEGc92XOgjR/ev5YbfruKLXtaWDClmg+9eiZvfsUUykp8toGZmQ08\nh7g8DnF2JPtb2/nZoy/wzXtXs/Kl3UysHsH7z6rn4tOnM66yLO3yzMxsGHGIy+MQZ73V0RH89rlm\nvnXvan733GbKshnOWziJixdN48xZ4z3UamZmBdfbEFcyEMWYDRaZjFg8bwKL501gxcZd3PjgOv7r\nkSaWPr6BmTWVXHz6NN526lQmVJWnXaqZmQ1zPhJndgT7W9u548kXufHBdTy0ZhsZwdlzarjw5Km8\nccFEqspL0y7RzMyGEA+n5nGIs/6y8qVd/OzRDfz88RdYv3UfI0oynHPCBJacNJXXHlfLyLJs2iWa\nmdkg5xCXxyHO+ltE8Oj67Sx9bAO3PbGBzbtbKC/N8Jq5tbxhwSTOOX4CY31BhJmZHQWHuDwOcVZI\nbe0d3L9qK796eiN3Pb2JF3fsJyM4vX4c55wwgdccV8u8iVW+KMLMzHrFIS6PQ5wNlIjgqRd2ctfT\nG7lr2SZWbNoFwISqEbx6bi2vOa6Gs+fUUDNqRMqVmplZsXKIy+MQZ2nZsH0f9z63md8+18y9Kzez\nfW8rACdMrmZR/VhOnzmORfXjmFDtq13NzCzHIS6PQ5wVg/aO4KkXdvDbZ5u5f/UWHlm7nX2t7QDU\nj6/g9PpxnD5zHKdOH8PMmlFkMx5+NTMbjhzi8jjEWTFqbe9g2YadPLR6Kw+u2cpDa7YePFJXWZZl\n4dTRnFg3mhPrxnBi3Wimj6vweXVmZsOAQ1wehzgbDDo6guebd/N40w6eaNrO4007WL5hJy3tHQCM\nqSjlhEnVzJtUxfGTqpg3qYrjJlZROcL37DYzG0r8xAazQSaTEXMnVjF3YhUXnVYHQEtbB89u2sXj\nTdt5smkHyzfu4scPrT84DAswbdxI5k2s5vhJVcyqrWRmTSWzakYxusI3ITYzG8oc4syKWFlJhoVT\nR7Nw6mh4ZW5eR0ewfttentm4i2c37uKZTbtYsXEXd694ifaOPx5ZH1dZxsyaykNe08ZWUDd2JGMq\nSj00a2Y2yHk41WyIaGnrYP22vaxu3sPqzXtYtXkPqzfvZvXmPWzaeeCQthVlWerGjmTqmJHUJcFu\najI9efRIakaVUZLNpLQlZmbDm4dTzYaZspIMs2tHMbt21MuW7TnQxpote2jato+mbft4Yds+mrbt\npWnbPh5Zt50d+1oPaS/B+MoRTKwewcTqciZWj6C2KvdzYlU5E6vLGT+qjHGVZZSX+lFjZmZpcIgz\nGwYqR5SwYMpoFkwZ3e3ynftbeSEJd5t27WfTzgO8tHM/m3buZ+OO/TzRtIMtew7Q3YH7irIs4yrL\nDn1VlDFuVBnjK8sYW1HG2MoyqstLqR5ZQnV5KRVlWQ/nmpkdI4c4M8sFrMmlnDC5usc2re0dbN59\ngE07D7Bp53627mk55LVlTwtbdrfw3KbdbN3TcsjFF11lM6K6vITqkaVUl5cyeuQfA15uXgmVI0qo\nLCuhYkQ297MsS+WIQ39WlJX4fnpmNmw5xJlZr5RmM0wenTtnrjf2tbSzdW8LW3e3sH1fCzv3tbFz\nfys797UmP/On29i0c//B+YcLgF2Vl2YOCXsjy7KUl2QpL81QXpplREnuZ3lplhGlGUZ0LivJJvPz\n5uVNl5VkKM1mKM0q+fnH38uyGTIOj2aWsoKGOEnnAV8BssA3I+LzPbS7CPgJcHpENCbzPgV8EGgH\nroiIO5P5HwM+BATwJPDnEbG/kNthZn03sizL1LLcxRJ91dLWwd6WNva0tLP3QJefLW3sOdDOngNt\n7GlpY29L7vf8nwfa2tm8u439re3sb2vnQGtH8nsHLW0d/bJ92YxyoS6TobTk0IBXms1QWpKEv8wf\nfy/JZMhmoCSTC4ElGZHNiKxENpubziiZn83Nz7XJrZfNZHJtknW79lGS/ePvmaSvjCAjoeRn5zx1\nLsvkTye/k9c+Q5d1etFnMk/56yZ9dlKXeSK3vjqXebjd7IgKFuIkZYHrgXOBJuAhSUsj4uku7aqA\nK4AH8ubNBy4GFgBTgP+RdBwwKWk7PyL2Sbo5affdQm2HmQ28spIMZSVljKno/747OoKW9iTUJeHu\nQFvndC7o7W9tp609aG3voKW9g9b2DlrbOmhL1m1tyy07dHnQ2tFBa3vQ2nbosv2tHeza30Zbe9De\nEbRH7mdbRwcdHdDW0ZGb3xG0dQQdyc/O6eEuF/j+GOwOBj1yC3RIO3Xbnq7z9PLgmPSSt+zgnJf1\nebCPzjq6qfll87rdtm7W7cWKR91Xj7X1bhv69T2PoY6Xf0ZHX0dffefS0xlTUXbsHfWDQh6JWwSs\njIhVAJJuAi4Enu7S7mrgGuDjefMuBG6KiAPAakkrk/7WJTWPlNQKVAAbCrgNZjbEZDKiPJMdVFfV\ndoa6jkjCXXsuCOaHv/xXZ9sI6IigI/kZnb935H5G3rLu2/emTf7ypH3HoX20Jz8Bgrzfk18ickMr\nuZ/5bXMzO5flr5/fvrNxJH12LqebPjvft6f3y/2eX+PL37OzDvLeJ193t+7qvl03846yr+5mRjcz\nu33PXqzbm1p7atddy973d+TtP5a+jkYxHSUuZIibCqzPm27i4O1KcySdAkyLiNskfbzLuvd3WXdq\nRNwn6Yvkwtw+4K6IuKu7N5d0GXAZwPTp0491W8zMUpPJiDKfg2dmXRTybp7d/RfnYAyWlAGuBa7s\n7bqSxpI7SjeT3DBrpaT3dPfmEXFDRDRERENtbW2fizczMzMrZoUMcU3AtLzpOg4d+qwCFgL3SFoD\nnAEsldRwmHVfD6yOiOaIaAX+CzirYFtgZmZmVqQKGeIeAuZKmimpjNwFCEs7F0bEjoioiYj6iKgn\nN3y6JLk6dSlwsaQRkmYCc4EHyQ2jniGpQrlB6XOA5QXcBjMzM7OiVLBz4iKiTdLlwJ3kbjHy7YhY\nJumzQGNELD3MusuSK0+fBtqAv46IduABSbcAjyTzHwVuKNQ2mJmZmRUr9dfVGsWsoaEhGhsb0y7D\nzMzM7IgkPRwRDUdqV8jhVDMzMzMrEIc4MzMzs0HIIc7MzMxsEHKIMzMzMxuEHOLMzMzMBiGHODMz\nM7NByCHOzMzMbBByiDMzMzMbhIbFzX4lNQNrC/w2NcDmAr+H9Z33S/HxPik+3ifFyful+AzUPpkR\nEbVHajQsQtxAkNTYm7sr28Dyfik+3ifFx/ukOHm/FJ9i2yceTjUzMzMbhBzizMzMzAYhh7j+c0Pa\nBVi3vF+Kj/dJ8fE+KU7eL8WnqPaJz4kzMzMzG4R8JM7MzMxsEHKI6weSzpO0QtJKSZ9Mu57hQtI0\nSXdLWi5pmaSPJvPHSfqVpOeSn2OT+ZL01WQ/PSHp1HS3YOiSlJX0qKTbkumZkh5I9smPJZUl80ck\n0yuT5fVp1j2USRoj6RZJzyTfmTP9XUmXpI8l/+16StKNksr9XRl4kr4t6SVJT+XN6/N3Q9L7k/bP\nSXr/QNTuEHeMJGWB64HzgfnAJZLmp1vVsNEGXBkRJwBnAH+dfPafBH4dEXOBXyfTkNtHc5PXZcDX\nBr7kYeOjwPK86S8A1yb7ZBvwwWT+B4FtETEHuDZpZ4XxFeCXEXE8cBK5/ePvSkokTQWuABoiYiGQ\nBS7G35U0fBc4r8u8Pn03JI0D/hl4JbAI+OfO4FdIDnHHbhGwMiJWRUQLcBNwYco1DQsR8WJEPJL8\nvovcP0pTyX3+30uafQ94a/L7hcD3I+d+YIykyQNc9pAnqQ54M/DNZFrA64BbkiZd90nnvroFOCdp\nb/1IUjXwGuBbABHREhHb8XclbSXASEklQAXwIv6uDLiI+C2wtcvsvn433gj8KiK2RsQ24Fe8PBj2\nO4e4YzcVWJ833ZTMswGUDC2cAjwATIyIFyEX9IAJSTPvq4HxZeATQEcyPR7YHhFtyXT+535wnyTL\ndyTtrX/NApqB7yTD3N+UVIm/K6mJiBeALwLryIW3HcDD+LtSLPr63UjlO+MQd+y6+z8hX/I7gCSN\nAn4K/G1E7Dxc027meV/1I0lvAV6KiIfzZ3fTNHqxzPpPCXAq8LWIOAXYwx+Hh7rj/VJgyVDbhcBM\nYApQSW6orit/V4pLT/shlf3jEHfsmoBpedN1wIaUahl2JJWSC3A/ioj/SmZv6hz6SX6+lMz3viq8\ns4ElktaQO7XgdeSOzI1Jhozg0M/94D5Jlo/m5cMaduyagKaIeCCZvoVcqPN3JT2vB1ZHRHNEtAL/\nBZyFvyvFoq/fjVS+Mw5xx+4hYG5yRVEZuRNTl6Zc07CQnA/yLWB5RHwpb9FSoPPKoPcDP8+b/77k\n6qIzgB2dh8utf0TEpyKiLiLqyX0X/jci3g3cDVyUNOu6Tzr31UVJex9d6GcRsRFYL2leMusc4Gn8\nXUnTOuAMSRXJf8s694m/K8Whr9+NO4E3SBqbHGV9QzKvoHyz334g6U3kjjZkgW9HxL+mXNKwIOlV\nwO+AJ/nj+Vf/SO68uJuB6eT+Q/mnEbE1+Q/ldeRONt0L/HlENA544cOEpMXAxyPiLZJmkTsyNw54\nFHhPRByQVA78gNz5jFuBiyNiVVo1D2WSTiZ3sUkZsAr4c3L/I+/vSkok/QvwTnJX2j8KfIjceVT+\nrgwgSTcCi4EaYBO5q0x/Rh+/G5I+QO7fIIB/jYjvFLx2hzgzMzOzwcfDqWZmZmaDkEOcmZmZ2SDk\nEGdmZmY2CDnEmZmZmQ1CDnFmZmZmg5BDnJkNepImSvpPSaskPSzpPklvS5YtlrQjedzU/9/e/YRa\nOsdxHH9/GfkTzYawokQaNc5kLBRGsRzjDolMapCFmLFgsDEbZTRLGQsLuURuY3GT7Bj5MwuLaSiM\nolvKyoaRJlN8LJ7fNE/HOXPnTBae0/tVt379/p+7+vb8nuf7+76qPm03S0yaZ0tVPdfKC1W17j/c\n46ilI/rXWpJ0Jtas3kWS/r9a3qZlYDHJA63uCmBLr9tnSTa3thGwXFXHknzUnyvJ+5xM1r0AfECX\ngPV097Kmd+/luBGwEfhwwlqSNDPzxEkatKq6HdidZNOU9ttoSYd7dQ8DdybZOtZ3O12g9Q5dAPdb\n+7unddkHXEKX5PPRJEeq6g265KsbgEPAEl3y7/OBY3RJdVeAH1rdz8CeVt6Y5IkWdL7e5v6FLoHo\nT23uo21PlwHPJHnvTP5PkuaPx6mShu46uuBpFoeAa6c1JjlI95RsV5JRkh+B14AdSW4AngZe7Q25\nBrgjyVPAEeDWdtH8buDFJMdbeanNtzS25CvAm0nWA28DL/faLgduBjYDL834OyXNMY9TJc2VqtpH\nF/QcT3LjtG4zznkh3eXk+7vTWwDO7XXZn+SvVl4LLFbV1UCAc05jiZuAu1v5LWBvr205yd/At1V1\n6Sz7ljTfDOIkDd03nDzuJMnjVXUxcKq7PjcA382wxlnAr0lGU9r/6JVfAA4k2VpVVwKfzLDOCf33\nXP7slWcKPiXNN49TJQ3dx8B5VfVYr+6CaZ2raj3wPN37bafyO3ARQJKjwEpV3dvmqKq6fsq4tXTv\nvQFsnzTfBAeB+1t5G/D5KnuTJIM4ScOW7uusBWBTVa1U1ZfAIvBsr9stJ1KM0AVvO8e/TJ3gXWBX\nG3cVXXD1SFV9Rff0764p4/YCe6rqC+DsXv0BYF1VHa6q+8bG7AQeqqqvgQeBJ1f73ZLk16mSJEkD\n5JM4SZKkATKIkyRJGiCDOEmSpAEyiJMkSRoggzhJkqQBMoiTJEkaIIM4SZKkATKIkyRJGqB/AIsJ\n8u74iLHeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пожалуйста, при использовании различных функций из библиотек импортируйте все, что вам понадобилось в данной части, в следующем блоке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, SelectFromModel, f_regression\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, PolynomialFeatures\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом домашнем задании вы поработаете с данными из другого соревнования на Kaggle: https://www.kaggle.com/c/house-prices-advanced-regression-techniques. Задача - предсказание цены дома."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.drop('Id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть ли в данных пропуски? Если да, то для каждого столбца, в котором они имеются, посчитайте их количество и их долю от общего числа значений. Что вы наблюдаете?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Избавьтесь от пропусков. Для каждого из примененных методов обоснуйте свое решение. **Проверьте, что вы действительно избавились от пропусков.**\n",
    "\n",
    "*Напоминание. В зависимости от типа столбца, можно заполнить пропуски, например, средним арифметическим, медианой, модой, можно какими-то отдельными значениями. А можно такие столбцы вообще удалить.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обработайте категориальные признаки. В их обнаружении вам может помочь синтаксис `pandas` (например, можно обратить внимание на типы столбцов), а также описание датасета и его исследование. Объясните выбор метода (one-hot-encoding, label encoding, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 (0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычислите и визуализируйте попарную корреляцию Пирсона между всеми признаками. Какие выводы можно сделать?\n",
    "\n",
    "*Для визуализации можно использовать `seaborn.heatmap()`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 (0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите признаки с максимальным и минимальным **абсолютным** значением коэффициента корреляции Пирсона с предсказываемым значением. Изобразите на графиках зависимость найденных признаков от предсказываемого значения.\n",
    "\n",
    "*Не забудьте указать название графика и обозначить, что изображено по каждой из осей.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 (0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте гистограмму распределения предсказываемого значения. Для избавления от разницы в масштабах, а также «смещения» распределения переменной в сторону нормального (что бывает полезно при статистическом анализе), можно прологарифмировать ее (это обратимое преобразование, поэтому целевую переменную легко восстановить). В данном случае воспользуйтесь `numpy.log1p`, чтобы сделать преобразование $y \\to \\ln\\left(1 + y\\right)$. Постройте гистограмму распределения от нового предсказываемого значения. Опишите наблюдения.\n",
    "\n",
    "*В дальнейшем используйте в качестве предсказываемого значения вектор, который получился после логарифмирования.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перейдем непосредственно к построению моделей. Разобьем выборку на обучение и контроль.\n",
    "\n",
    "*Пожалуйста, **не меняйте** значение `random_state` в следующей ячейке.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=17032019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примените к данным следующие алгоритмы:\n",
    "\n",
    "- kNN\n",
    "- линейная регрессия\n",
    "- Lasso\n",
    "- Ridge\n",
    "\n",
    "Для каждого из методов подберите гиперпараметры с помощью кросс-валидации. Обучите алгоритмы с лучшими гиперпараметрами на обучающей выборке и оцените качество по метрике **Root** Mean Squared Error. Какой из методов показывает себя лучше?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте гистограммы значений весов для линейной регрессии, Lasso и Ridge. Опишите наблюдения. В чем различия между полученными наборами весов и почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 (0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добейтесь того, чтобы в заданиях выше ваш лучший алгоритм давал качество не больше 0.125 на тестовых данных по метрике RMSE (если вы дошли до этого задания, а качество выше уже удовлетворяет этому условию, вы автоматически получите за него полный балл)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10* (0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добейтесь того, чтобы в заданиях выше ваш лучший алгоритм давал качество не больше 0.121 на тестовых данных по метрике RMSE. Для этого вы можете использовать самые разные методы, какие захотите - отбор признаков, генерация новых, разные способы предобработки данных. Единственное ограничение - не использовать никакие алгоритмы регрессии, кроме kNN, линейной регрессии, Lasso и Ridge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11* (0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По аналогии с первым домашним заданием, вы можете получить бонус за отправку посылки в соревнование на Kaggle. Не забудьте преобразовать тестовые данные так же, как и обучающую выборку, а также сделать обратное преобразование целевой переменной относительно логарифмирования (с помощью `numpy.expm1`). Запишите ваш результат, а также при сдаче задания в Anytask прикрепите скриншот вашего положения в таблице участников."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат семинариста: 0.13105\n",
    "\n",
    "Ваш результат: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Теория (бонусная часть)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "За данную часть можно получить бонусные баллы. Решения необходимо оформить в этом же файле в ячейках типа Markdown, пользуясь $\\LaTeX$ для записи математических формул."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1* (0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите константу $C$, решающую следующую задачу ($0 < \\tau < 1$ фиксировано):\n",
    "\n",
    "$$\n",
    "\\sum\\limits_{i=1}^\\ell\\rho_\\tau\\left(y_i - C\\right) \\to \\min_C,\n",
    "$$\n",
    "\n",
    "где\n",
    "\n",
    "$$\n",
    "\\rho_\\tau(z) =\n",
    "\\begin{cases}\n",
    "\\tau z, & z > 0\\\\\n",
    "(\\tau - 1)z, & z \\leq 0\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(your solution here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2* (0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гарри Поттер хочет найти философский камень, расположенный в точке минимума функции $f(x_1, x_2)=x_1^2 + x_2^2$. В момент времени 0 он стартует из точки $x^{(0)}=(2, 2)$. На $i$-й минуте Гарри мгновенно перемещается (аппарирует) из точки $x^{(i)}$ в точку\n",
    "\n",
    "$$\n",
    "x^{(i+1)} = x^{(i)} - \\eta \\nabla f(x^{(i)}),\n",
    "$$\n",
    "\n",
    "где $\\nabla f(x^{(i)})$ — градиент $f$ в точке $x^{(i)}$, $\\eta \\ge 0$ — фиксированное число. Опишите судьбу Гарри в зависимости от значения $\\eta$. При каких значениях $\\eta$ Гарри подойдёт к философскому камню сколь угодно близко? Сколько итераций ему понадобится, чтобы подойти к философскому камню на расстояние не больше $\\varepsilon$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(your solution here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3* (0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим задачу обучения линейной регрессии:\n",
    "\n",
    "$$\n",
    "Q(w) = \\frac{1}{2}(y - Xw)^T(y - Xw) \\to \\min_w\n",
    "$$\n",
    "\n",
    "Будем решать ее с помощью градиентного спуска. Допустим, мы находимся на некоторой итерации $k$ и хотим выполнить очередной шаг\n",
    "\n",
    "$$\n",
    "w^{(k)} = w^{(k - 1)} - \\eta\\nabla_wQ\\left(w^{(k - 1)}\\right)\n",
    "$$\n",
    "\n",
    "При известных $y$, $X$ и $w^{(k - 1)}$ найдите длину шага $\\eta$, при которой уменьшение значения функционала будет наибольшим:\n",
    "\n",
    "$$\n",
    "Q\\left(w^{(k - 1)} - \\eta\\nabla_wQ\\left(w^{(k - 1)}\\right)\\right) \\to \\min_\\eta\n",
    "$$\n",
    "\n",
    "*Примечание 1. $\\nabla_wQ = -X^T\\left(y - Xw\\right)$.*\n",
    "\n",
    "*Примечание 2. Для получения лаконичного ответа вам, возможно, поможет следующее свойство скалярного произведения. Пусть $x_1$, $x_2$ - вектора, а $A$ - матрица. Тогда выполняется равенство:*\n",
    "\n",
    "$$\n",
    "\\langle x_1, Ax_2\\rangle = \\langle A^Tx_1, x_2\\rangle\n",
    "$$\n",
    "\n",
    "*Это верно потому, что $\\langle x_1, Ax_2\\rangle = x_1^TAx_2 = \\left(A^Tx_1\\right)^Tx_2 = \\langle A^Tx_1, x_2\\rangle$.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(your solution here)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
