{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семинар 3-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм KNN является надежным и универсальным классификатором, который часто используется в качестве бейзлайна для более сложных классификаторов, таких как искусственные нейронные сети (ANN). Несмотря на свою простоту, KNN может превзойти более мощные классификаторы и используется во множестве приложений, таких как экономическое прогнозирование, сжатие данных и генетика. Например, KNN использовалась в [исследовании](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-7-S1-S11) по функциональной геномике в 2006 году, где гены определялись на основе их профилей экспрессии.\n",
    "\n",
    "# Что такое алгоритм KNN?\n",
    "\n",
    "Начнем с введения некоторых определений и обозначений.\n",
    "\n",
    "* Мы будем использовать $x$ для обозначения вектора признаков (или атрибутов) объекта.\n",
    "* Под $y$ мы будем подразумевать метку или класс, который мы пытаемся предсказать.\n",
    "\n",
    "KNN входит в число **supervised** алгоритмов или алгоритмов \"обучения с учителем\".\n",
    "Это означает, что нам предоставляется размеченный набор данных, для которого известны соответствия между наблюдениями $(x, y)$. Целью является на основе предоставляемой выборки найти связь между $x$ и $y$, чтобы восстановить функцию $h: X \\rightarrow Y$. Имея такую функцию, мы можем предсказать $y$ по имеющемуся наблюдению $x$.\n",
    "\n",
    "Обучение KNN заключается в запоминании экземпляров обучающей выборки, которые впоследствии используются как «знание» для фазы прогнозирования. Конкретно это означает, что только когда запрос в нашу базу данных сделан (т.е. когда мы просим KNN предсказать метку с учетом ввода), алгоритм будет использовать экземпляры обучения, чтобы выдать ответ.\n",
    "\n",
    "Нужно понимать, что фаза обучения, заключающаяся в запоминании объектов выборки не является дорогостоящей по времени.\n",
    "Однако этого нельзя сказать о фазе тестирования. Если база обучения достаточно большая, осуществление поиска по ней достаточно дорогостоящий процесс.\n",
    "\n",
    "\n",
    "# Как KNN работает?\n",
    "\n",
    "В случае классификации алгоритм K-ближайших соседей по существу сводится к подсчету большинства голосов между K наиболее похожими экземплярами для данного тестового экземпляра. Сходство экземпляров определяется по расстоянию между двумя точками данных. Популярным выбором является евклидово расстояние, но другие меры близости также могут быть подходящими для конкретной ситуации, включая расстояние Манхэттен, Чебышева и Хэмминга.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "class0 = np.random.normal(4, 2, size=100).reshape(-1, 2)\n",
    "class1 = np.random.normal(2, 1.5, size=100).reshape(-1, 2)\n",
    "data = np.vstack((class0, class1))\n",
    "target = np.hstack((np.zeros(len(class0)), np.ones(len(class1)))).astype(int)\n",
    "plt.scatter(data[:, 0], data[:, 1], c=target, cmap='bwr')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install mlxtend`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_decision_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_decision_regions\n",
    "plot_decision_regions(X=data, y=target, clf=knn, legend=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте поменять параметр `n_neighbors` у классификатора kNN. Что получается, когда соседей очень мало? Когда очень много? Как меняется граница между классами?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет: https://www.openml.org/d/31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset_31_credit-g.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.drop('class', axis=1)\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes(exclude=['object']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.select_dtypes(exclude=['object'])\n",
    "y = df['class']\n",
    "knn.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y, knn.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стоп. А все ли мы правильно делаем? Этому ответу вообще можно доверять?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В реальности нам вряд ли нужен алгоритм, который будет корректно классифицировать те же самые объекты, ответы для которых мы и так знаем. Поэтому в машинном обучении важно настраивать алгоритмы и оценивать их качество на разных выборках.\n",
    "\n",
    "Однако откуда нам их взять, если выборка у нас всего одна?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train, y_train)\n",
    "accuracy_score(y_train, knn.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, knn.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном случае мы оценивали качество не по всей выборке, а лишь по ее части. Как же оценить по всей?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Кросс-валидация (Скользящий контроль)**\n",
    "\n",
    "Контроль по $k$ блокам (**k-fold CV**): выборка случайным образом разбивается на $k$ непересекающихся блоков одинаковой (или почти одинаковой) длины. Затем на каждом шаге один из блоков используется для оценки качества, а остальные - для обучения.\n",
    "\n",
    "<img src=\"https://codesachin.files.wordpress.com/2015/08/cv.png\" width=\"400\" align=\"center\">\n",
    "\n",
    "**Оценкой скользящего контроля** называется средняя по всем разбиениям величина ошибки на контрольных подвыборках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cross_val_score(knn, X, y, cv=kf, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# что будет, если увеличить число соседей? Попробуйте! (Менять от 5 до 200)\n",
    "knn = KNeighborsClassifier(n_neighbors=200)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cross_val_score(knn, X, y, cv=kf, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train, y_train)\n",
    "knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = np.arange(1, 201, 2)\n",
    "\n",
    "scores_uni = []\n",
    "scores_dis = []\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "for k in neighbors:\n",
    "    knn_uniform = KNeighborsClassifier(n_neighbors=k, weights='uniform')\n",
    "    knn_distance = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
    "    scores_uni.append(cross_val_score(knn_uniform, X, y, cv=kf, scoring='accuracy').mean())\n",
    "    scores_dis.append(cross_val_score(knn_distance, X, y, cv=kf, scoring='accuracy').mean())\n",
    "    \n",
    "plt.plot(neighbors, scores_uni, label='uniform')\n",
    "plt.plot(neighbors, scores_dis, label='distance')\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "params = {'n_neighbors': np.arange(1, 201, 2), 'weights': ['uniform', 'distance']}\n",
    "clf = GridSearchCV(knn, params, cv=kf, scoring='accuracy')\n",
    "clf.fit(X, y)\n",
    "clf.best_params_, clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = df.select_dtypes(include=['object']).columns\n",
    "numerics = df.select_dtypes(include=['object']).columns\n",
    "categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(df['checking_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.transform(df['checking_status'])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.inverse_transform(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.fit_transform(df['checking_status'])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задания для самостоятельной работы\n",
    "\n",
    "1. Закодируйте категориальные признаки в исходной таблице `df` с помощью `LabelEncoder`.\n",
    "2. Подберите оптимальные параметры `k` и `distance` для kNN. Какое качество показывает алгоритм?\n",
    "3. Проделайте первый шаг, но с one-hot-кодированием (функция `get_dummies` из `pandas`). Повторите шаг 2. Что работает лучше? Выберите лучший с точки зрения результатов метод кодирования.\n",
    "4. Сравните способы масштабирования `MinMaxScaler` и `StandardScaler` друг с другом, и проделайте для полученных данных шаг 2 еще раз. Какое получилось качество?\n",
    "\n",
    "_(набор заданий считается сделанным, если итоговое качество превышает 0.72)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ﾉ◕ヮ◕)ﾉ*:･ﾟ✧ ✧ﾟ･: *ヽ(◕ヮ◕ヽ)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
