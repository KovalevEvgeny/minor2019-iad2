{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семинар 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Линейная регрессия: напоминание\n",
    "\n",
    "В задаче линейной регрессии мы предполагаем, что ответ является линейной функцией от данных, то есть\n",
    "\n",
    "$$y = w_1 x_1 + \\ldots + w_m x_m = \\langle x, w\\rangle,$$\n",
    "\n",
    "* Здесь $\\langle\\cdot, \\cdot\\rangle$ — скалярное произведение.\n",
    "* $w_i$ — вес i-ого признака в модели линейной регрессии. \n",
    "    * $w=(w_1, \\ldots, w_m)$ — вектор весов признаков.\n",
    "* $x_i$ — значение i-ого признака во входном $x$ \n",
    "\n",
    "Распространенным способом обучения линейной регрессионной модели является метод наименьших квадратов. При использовании этого метода минимизируется *квадратичная функция потерь*:\n",
    "\n",
    "$$Q(w) = \\sum_{j=1}^n Q_j(w) = \\sum_{j=1}^n ( \\langle x^j, w\\rangle - y^j)^2$$\n",
    "\n",
    "Здесь $n$ — число элементов в обучающей выборке.\n",
    "\n",
    "Явная формула для вектора весов, решающая минимизационную задачу:\n",
    "\n",
    "$$w = (X^T X)^{-1} X^T y,$$\n",
    "\n",
    "где $X$ — матрица объект-признак (по строкам объекты, по столбцам признаки), $y$ — вектор правильных ответов.\n",
    "\n",
    "Эта формула очень полезна для теоретического анализа, но имеет некоторые ограничения:\n",
    "\n",
    "1. В ней используется «дорогая» операция — обращение матрицы размером $d\\times d$, где $d$ — количество признаков. Она занимает $O(d^3)$ операций, и если $d$ большое, может быть довольно медленной.\n",
    "2. Эта формула выведена в предположении именно квадратичной функции потерь. Если мы захотим использовать другую формулу потерь, она не работает (и не всегда можно вывести такую явную формулу, которая бы работала). \n",
    "\n",
    "Вместо использования явной формулы можно предложить другой подход — минимизация $Q$ с помощью итеративных методов. Простейшим из них является метод градиентного спуска. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим функцию $f(x, y)=x^2 + 10 y^2$. Её градиент равен $\\nabla f(x, y)=\\frac{\\partial f(x, y)}{\\partial(x, y)}=(2x, 20y)$. Он показывает направление наискорейшего роста функции, то есть отвечает на вопрос «куда нам идти, если мы находимся в точке $(x, y)$ и хотим увеличивать значение функции как можно быстрее». Чтобы уменьшать значение функции, нужно идти в противоположном направлении. В связи с этим, напрашивается такой алгоритм нахождения минимума функции $f$:\n",
    "\n",
    "1. Возьмём любую точку $(x_0, y_0)$. Посчитаем градиент в этой точке.\n",
    "\n",
    "2. Для каждого $i=1, \\ldots$, положим: $(x_{i+1}, y_{i+1})=(x_i, y_i) - \\eta \\nabla f(x_i, y_i)$, где $\\eta$ — какое-то число (небольшое).\n",
    "\n",
    "3. Будем продолжать вычислять очередную точку $(x_i, y_i)$ до тех пор, пока мы не окажемся достаточно близко к минимуму — например, до тех пор, пока градиент не слишком маленький."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(u):\n",
    "    return u[0] ** 2 + 10 * u[1] ** 2\n",
    "def Df(u):\n",
    "    return np.array([2*u[0], 20 * u[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задания для самостоятельного решения\n",
    "\n",
    "1. Допишите код для функции градиентного спуска.\n",
    "2. Попробуйте поизменять основные параметры функции (`eta`, `initial_point`, `precision`). Что вы наблюдаете?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(f, Df, eta=0.01, steps=20000, initial_point=(-3, 3), precision=1e-10,\n",
    "                            xmin=-4, xmax=4, ymin=-3, ymax=3):\n",
    "    \n",
    "    u_prev = np.array(initial_point)\n",
    "\n",
    "    X = np.linspace(xmin, xmax, 100)\n",
    "    Y = np.linspace(ymin, ymax, 100)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.contour(X, Y, [[f(np.array([x, y])) for x in X] for y in Y], 100)\n",
    "    # нарисуем линии уровня функции $f$\n",
    "\n",
    "    points = []\n",
    "    for i in range(steps):\n",
    "        # ( ͡° ͜ʖ ͡°)\n",
    "\n",
    "    plt.plot([p[0] for p in points], [p[1] for p in points], 'o-')\n",
    "    \n",
    "    return points[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gradient_descent(f=f, Df=Df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный спуск и линейная регрессия\n",
    "\n",
    "Пусть идеальная зависимость задается следующим образом: $y = kx + b$, где $k = 4$ и $b = 3$. Добавим к данным немного шума из нормального распределения и постараемся восстановить параметры $w = (k, b)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "\n",
    "# сгенерировали n примеров x из нормального распределения\n",
    "x = np.random.normal(size=n)\n",
    "\n",
    "# генерируем зависимость с добавлением шума\n",
    "y = 4 * x + 3 + 1.5 * np.random.normal(size=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# посмотрим, что у нас за данные\n",
    "plt.plot(x, y, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задания для самостоятельного решения\n",
    "\n",
    "Решите задачу по восстановлению параметров с помощью линейной регрессии. В качестве метода оптимизации используйте написанный выше градиентный спуск. Для этого:\n",
    "\n",
    "1. Подготовьте выборку для решения задачи.\n",
    "2. Реализуйте функцию потерь в векторном виде.\n",
    "3. Реализуйте градиент функции потерь в векторном виде.\n",
    "4. Примените метод градиентного спуска к полученным функциям и получите ответ. Сравните его с исходными параметрами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Матрично-векторное дифференцирование: https://yadi.sk/i/SSWQ8b3x3RGuPr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ( ͡°( ͡° ͜ʖ( ͡° ͜ʖ ͡°)ʖ ͡°) ͡°)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Линейная регрессия на реальных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://archive.ics.uci.edu/ml/datasets/communities+and+crime\n",
    "\n",
    "data = pd.read_csv('communities (2).csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data.drop(['ViolentCrimesPerPop'], axis=1)\n",
    "y = data['ViolentCrimesPerPop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = pd.DataFrame(data=np.array([X.columns, lr.coef_]).T, columns=['feature', 'weight'])\n",
    "w[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_pred = lr.predict(X_train)\n",
    "test_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print('Train MSE:', mean_squared_error(y_train, train_pred))\n",
    "print('Test MSE:', mean_squared_error(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В чем же дело?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w.sort_values(by='weight')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w.sort_values(by='weight', ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train['PolicPerPop'].corr(X_train['LemasSwFTPerPop'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как решить эту проблему?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_new = X_train.drop('LemasSwFTPerPop', axis=1)\n",
    "X_test_new = X_test.drop('LemasSwFTPerPop', axis=1)\n",
    "lr.fit(X_train_new, y_train)\n",
    "\n",
    "train_pred = lr.predict(X_train_new)\n",
    "test_pred = lr.predict(X_test_new)\n",
    "print('Train MSE:', mean_squared_error(y_train, train_pred))\n",
    "print('Test MSE:', mean_squared_error(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_new = pd.DataFrame(data=np.array([X_train_new.columns, lr.coef_]).T, columns=['feature', 'weight'])\n",
    "w_new.sort_values(by='weight')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_new.sort_values(by='weight', ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1-регуляризация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "las = Lasso(alpha=0.01)\n",
    "las.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_pred = las.predict(X_train)\n",
    "test_pred = las.predict(X_test)\n",
    "print('Train MSE:', mean_squared_error(y_train, train_pred))\n",
    "print('Test MSE:', mean_squared_error(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_las = pd.DataFrame(data = np.array([X.columns, las.coef_]).T, columns= ['feature', 'weight'])\n",
    "w_las.sort_values(by='weight')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_las.sort_values(by='weight', ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2-регуляризация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "rid = Ridge(alpha=0.01)\n",
    "rid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_pred = rid.predict(X_train)\n",
    "test_pred = rid.predict(X_test)\n",
    "print('Train MSE:', mean_squared_error(y_train, train_pred))\n",
    "print('Test MSE:', mean_squared_error(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_rid = pd.DataFrame(data = np.array([X.columns, rid.coef_]).T, columns= ['feature', 'weight'])\n",
    "w_rid.sort_values(by='weight')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_rid.sort_values(by='weight', ascending=False)[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
