{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семинар 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для тех, кому интересно векторное дифференцирование и почему в линейной регрессии оптимальная оценка весов равна $w = \\left(X^TX\\right)^{-1}X^Ty$:\n",
    "\n",
    "- http://www.machinelearning.ru/wiki/images/5/50/MOMO17_Seminar2.pdf\n",
    "- https://github.com/esokolov/ml-course-hse/blob/master/2017-fall/seminars/sem02-linregr-part1.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Теория"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/esokolov/ml-minor-hse/blob/master/colloquium-2017/colloquium_minor_problems_linear.pdf\n",
    "\n",
    "Задачи 1, 3, 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы поработаем с данными о сообществах в США. Описание датасета:\n",
    "\n",
    "http://archive.ics.uci.edu/ml/datasets/communities+and+crime\n",
    "\n",
    "Датасет на кэггле (в формате .csv):\n",
    "\n",
    "https://www.kaggle.com/kkanda/communities%20and%20crime%20unnormalized%20data%20set\n",
    "\n",
    "Будем предсказывать количество насильственных преступлений относительно численности населения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('crimedata.csv', na_values=[\"?\"])\n",
    "# будем работать не со всеми колонками\n",
    "requiredColumns = [5, 6] + list(range(11,26)) + list(range(32, 103)) + [145]\n",
    "data = data[data.columns[requiredColumns]]\n",
    "# некоторые значения целевой переменной пропущены\n",
    "X = data.loc[data['ViolentCrimesPerPop'].notnull(), :].drop('ViolentCrimesPerPop', axis=1)\n",
    "y = data['ViolentCrimesPerPop'][X.index]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим линейную регрессию и выведем качество по метрике MSE на обучающей и тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_train,y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, lr.predict(X_train))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, lr.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим регуляризатор и посмотрим, изменилось ли качество. В качестве метода регуляризации используем Ridge ($L_2$-регуляризация)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(5.0).fit(X_train,y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, ridge.predict(X_train))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, ridge.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А что изменится при нормировании признаков? Попробуем MinMaxScaler. Есть ли разница? Влияет ли нормирование на качество линейной регрессии? А на качество регуляризованной? Почему так?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = MinMaxScaler()\n",
    "X_train_scaled = pd.DataFrame(data=sc.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(data=sc.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_train_scaled,y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, lr.predict(X_train_scaled))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, lr.predict(X_test_scaled))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(5.0).fit(X_train_scaled,y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, ridge.predict(X_train_scaled))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, ridge.predict(X_test_scaled))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 High/low variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полезны ли признаки, имеющие высокую дисперсию? А низкую?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_variance = X_train_scaled.var().sort_values(ascending=False)\n",
    "features_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем удалить признаки с самой низкой дисперсией и посмотреть, как изменится качество. В `sklearn` есть специальный инструмент для такого наивного отбора признаков. Стоит ли нормализовать перед этим признаки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# можно убрать все признаки, вариативность которых меньше заданного значения\n",
    "vs_transformer = VarianceThreshold(0.01)\n",
    "X_train_var = pd.DataFrame(data=vs_transformer.fit_transform(X_train_scaled), columns=X_train_scaled.columns[vs_transformer.get_support()])\n",
    "X_test_var = pd.DataFrame(data=vs_transformer.transform(X_test_scaled), columns=X_test_scaled.columns[vs_transformer.get_support()])\n",
    "\n",
    "X_train_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_train_var,y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, lr.predict(X_train_var))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, lr.predict(X_test_var))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(5.0).fit(X_train_var,y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, ridge.predict(X_train_var))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, ridge.predict(X_test_var))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно выбрать k признаков, которые дают наиболее высокие значения корреляции с целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# Выбираем 15 лучших признаков\n",
    "sb = SelectKBest(f_regression, k=15)\n",
    "\n",
    "X_train_kbest = pd.DataFrame(data=sb.fit_transform(X_train_var, y_train), columns=X_train_var.columns[sb.get_support()])\n",
    "X_test_kbest = pd.DataFrame(data=sb.transform(X_test_var), columns=X_test_var.columns[sb.get_support()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_train_kbest,y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, lr.predict(X_train_kbest))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, lr.predict(X_test_kbest))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(5.0).fit(X_train_kbest,y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, ridge.predict(X_train_kbest))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, ridge.predict(X_test_kbest))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А можно выбрать самые значимые признаки с точки зрения регрессии с $L_1$-регуляризацией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "lasso = Lasso(5.0)\n",
    "l1_select = SelectFromModel(lasso)\n",
    "\n",
    "X_train_l1 = pd.DataFrame(data=l1_select.fit_transform(X_train_var, y_train), columns=X_train_var.columns[l1_select.get_support()])\n",
    "X_test_l1 = pd.DataFrame(data=l1_select.transform(X_test_var), columns=X_test_var.columns[l1_select.get_support()])\n",
    "\n",
    "X_train_l1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_train_l1,y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, lr.predict(X_train_l1))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, lr.predict(X_test_l1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(5.0).fit(X_train_l1,y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, ridge.predict(X_train_l1))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, ridge.predict(X_test_l1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А можно сделать все вышеописанное сразу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('variance', VarianceThreshold(0.01)),\n",
    "    ('selection', SelectFromModel(Lasso(5.0))),\n",
    "    ('regressor', Ridge(5.0))\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "pipe.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Train: {}\".format(mean_squared_error(y_train, pipe.predict(X_train))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, pipe.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно также настраивать параметры с помощью `GridSearch`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'variance__threshold': [0.005, 0.0075, 0.009, 0.01, 0.011, 0.012],\n",
    "    'selection__estimator__alpha': [0.1, 0.5, 1.0, 1.5, 2.0, 5.0, 10.0],\n",
    "    'regressor__alpha': [0.1, 0.5, 1.0, 1.5, 2.0, 5.0, 10.0]\n",
    "}\n",
    "grid_search = GridSearchCV(pipe, param_grid, iid=False, cv=5)\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_best = grid_search.best_estimator_\n",
    "pipe_best.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_best.fit(X_train, y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, pipe_best.predict(X_train))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, pipe_best.predict(X_test))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
