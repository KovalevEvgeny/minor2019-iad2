{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семинар 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Решающие деревья"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='tree_example.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сами по себе решающие деревья используются в машинном обучении относительно редко, однако очень распространены методы, основанные на их композиции - ансамблях (Random Forest, XGBoost, LightGBM)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Плюсы:\n",
    "\n",
    "- интерпретируемость\n",
    "- способность выделить самые важные признаки\n",
    "- отсутствие потребности в серьезной предобработке данных\n",
    "\n",
    "##### Минусы:\n",
    "\n",
    "- склонность к переобучению\n",
    "- неустойчивость - небольшие изменения в данных могут привести к сильному изменению в структуре дерева\n",
    "- эвристичность обучения - как оптимизировать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Линейная модель vs \"деревянная\" модель (основанная на решающих деревьях):\n",
    "\n",
    "- когда данные хорошо линейно разделимы, линейная модель лучше\n",
    "\n",
    "- когда данные плохо линейно разделимы (много сложных нелинейных зависимостей в данных), \"деревянная\" модель лучше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Переобучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_grid(data):\n",
    "    x_min, x_max = data[:, 0].min() - 1, data[:, 0].max() + 1\n",
    "    y_min, y_max = data[:, 1].min() - 1, data[:, 1].max() + 1\n",
    "    return np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                         np.arange(y_min, y_max, 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(13)\n",
    "data_x = np.random.normal(size=(100, 2))\n",
    "data_y = (data_x[:, 0] ** 2 + data_x[:, 1] ** 2) ** 0.5 # \n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(data_x[:, 0], data_x[:, 1], c=data_y, s=100, cmap='spring')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "clf = DecisionTreeRegressor(random_state=13)\n",
    "clf.fit(data_x, data_y)\n",
    "\n",
    "xx, yy = get_grid(data_x)\n",
    "\n",
    "predicted = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pcolormesh(xx, yy, predicted, cmap='spring')\n",
    "plt.scatter(data_x[:, 0], data_x[:, 1], c=data_y, s=100, cmap='spring', edgecolor='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как будет выглядеть разделение плоскости в зависимости от максимальной глубины дерева и минимального числа объектов в листе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 14))\n",
    "for i, max_depth in enumerate([2, 4, None]):\n",
    "    for j, min_samples_leaf in enumerate([15, 5, 1]):\n",
    "        clf = DecisionTreeRegressor(max_depth=max_depth, min_samples_leaf=min_samples_leaf, random_state=13)\n",
    "        clf.fit(data_x, data_y)\n",
    "        xx, yy = get_grid(data_x)\n",
    "        predicted = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "        \n",
    "        plt.subplot2grid((3, 3), (i, j))\n",
    "        plt.pcolormesh(xx, yy, predicted, cmap='spring')\n",
    "        plt.scatter(data_x[:, 0], data_x[:, 1], c=data_y, s=30, cmap='spring', edgecolor='k')\n",
    "        plt.title('max_depth=' + str(max_depth) + ' | min_samples_leaf=' + str(min_samples_leaf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Неустойчивость"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как будет меняться структура дерева, если брать для обучения разные 90%-ые подвыборки исходной выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "for i in range(3):\n",
    "    clf = DecisionTreeRegressor(random_state=13)\n",
    "\n",
    "    indecies = np.random.randint(data_x.shape[0], size=int(data_x.shape[0] * 0.9))\n",
    "    clf.fit(data_x[indecies], data_y[indecies])\n",
    "    xx, yy = get_grid(data_x)\n",
    "    predicted = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "    plt.subplot2grid((1, 3), (0, i))\n",
    "    plt.pcolormesh(xx, yy, predicted, cmap='winter')\n",
    "    plt.scatter(data_x[:, 0], data_x[:, 1], c=data_y, s=30, cmap='winter', edgecolor='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Практика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(boston['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(boston['target'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(boston['data'], columns=boston['feature_names'])\n",
    "X['target'] = boston['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$R_m$ - множество объектов в разбиваемой вершине, $i$ - номер признака, по которому происходит разбиение, $t$ - порог разбиения.\n",
    "\n",
    "Качество:\n",
    "\n",
    "$$\n",
    "Q(R_m, i, t) = H(R_m) - \\frac{|R_\\ell|}{|R_m|}H(R_\\ell) - \\frac{|R_r|}{|R_m|}H(R_r)\n",
    "$$\n",
    "\n",
    "$R_\\ell$ - множество объектов в левом поддереве, $R_r$ - множество объектов в правом поддереве.\n",
    "\n",
    "$H(R)$ - критерий информативности, с помощью которого можно оценить качество распределения целевой переменной среди объектов множества $R$.\n",
    "\n",
    "_Вопрос. Что мы хотим сделать с $H(R)$ - минимизировать или максимизировать? А $Q(R_m, i, t)$?_\n",
    "\n",
    "_Вопрос. Что можно использовать в качестве критерия информативности для регрессии?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Реализуйте подсчет качества разбиения._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def H(R):\n",
    "    pass\n",
    "\n",
    "\n",
    "def split_node(R_m, feature, t):\n",
    "    pass\n",
    "\n",
    "\n",
    "def quality(R_m, feature, t):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Переберите все возможные разбиения выборки по одному из признаков и постройте график качества разбиения в зависимости от значения порога._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = # ʕ•ᴥ•ʔ\n",
    "Q_array = []\n",
    "for t in np.unique(X[feature]):\n",
    "    Q_array.append(quality(X, feature, t))\n",
    "plt.plot(Q_array)\n",
    "plt.title(feature)\n",
    "plt.xlabel('threshold')\n",
    "plt.ylabel('quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Напишите функцию, находящую оптимальное разбиение данной вершины по данному признаку._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_optimal_split(R_m, feature):\n",
    "    values = np.unique(R_m[feature])\n",
    "    Q_array = np.array(list(map(lambda t: quality(R_m, feature, t), values)))\n",
    "    opt_threshold = #ʕ•ᴥ•ʔ\n",
    "    return opt_threshold, Q_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, Q_array = get_optimal_split(X, feature)\n",
    "plt.plot(Q_array)\n",
    "plt.title(feature)\n",
    "plt.xlabel('threshold')\n",
    "plt.ylabel('quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Постройте график качества разбиения (в зависимости от количества объектов в левом поддереве) для каждого из признаков. Найдите признак, показывающий наилучшее качество. Какой это признак? Каков порог разбиения и значение качества? Постройте график качества разбиения для данного признака в зависимости от значения порога._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in boston['feature_names']:\n",
    "    t, Q_array = get_optimal_split(X, f)\n",
    "    print(f, t)\n",
    "    plt.plot(Q_array, label=f + ' {0:.2f}'.format(Q_array.max()))\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Изобразите разбиение визуально. Для этого постройте диаграмму рассеяния целевой переменной в зависимости от значения найденного признака. Далее изобразите вертикальную линию, соответствующую разбиению. Почему это разбиение может быть лучшим? Как вы можете интерпретировать результат?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter('#ʕ•ᴥ•ʔ')\n",
    "plt.axvline('#ʕ•ᴥ•ʔ', color=\"red\")\n",
    "plt.xlabel('#ʕ•ᴥ•ʔ')\n",
    "plt.ylabel('target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Многоклассовая классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris['data'], columns=iris['feature_names'])\n",
    "y = iris['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=13)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Понятно, что accuracy можно использовать как метрику качества не только в задаче бинарной классификации, но и в задаче многоклассовой классификации. Но что делать с precision, recall, f1? Можно сделать предсказание и воспользоваться какой-то из стратегий ниже.\n",
    "\n",
    "#### Микро-усреднение (micro-average)\n",
    "\n",
    "1) Считаются характеристики TP, FP, TN, FN для каждого класса.\n",
    "\n",
    "2) Характеристики TP, FP, TN, FN усредняются по всем классам.\n",
    "\n",
    "3) Метрики считаются по усредненным характеристикам.\n",
    "\n",
    "Например, в случае precision:\n",
    "\n",
    "$$\n",
    "Precision = \\frac{\\sum\\limits_{k}TP_k}{\\sum\\limits_{k}TP_k + \\sum\\limits_{k}FP_k},\n",
    "$$\n",
    "\n",
    "где $TP_k$ и $FP_k$ - TP и FP для класса $k$ соответственно.\n",
    "\n",
    "#### Макро-усреднение (macro-average)\n",
    "\n",
    "1) Считаются характеристики TP, FP, TN, FN для каждого класса.\n",
    "\n",
    "2) Считаются метрики для каждого класса.\n",
    "\n",
    "3) Итоговые метрики равны средним посчитанных метрик.\n",
    "\n",
    "В данном случае precision считается так:\n",
    "\n",
    "$$\n",
    "Precision = \\frac{\\sum\\limits_{k}Precision_k}{K},\n",
    "$$\n",
    "\n",
    "где $Precision_k$ - значение precision для класса $k$, а $K$ - общее число классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(estimator, X=X_test, y=y_test):\n",
    "    y_pred = estimator.predict(X)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision_micro = precision_score(y_test, y_pred, average='micro')\n",
    "    precision_macro = precision_score(y_test, y_pred, average='macro')\n",
    "    recall_micro = recall_score(y_test, y_pred, average='micro')\n",
    "    recall_macro = recall_score(y_test, y_pred, average='macro')\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    columns = ['accuracy', 'precision_micro', 'precision_macro', 'recall_micro', 'recall_macro', 'f1_micro', 'f1_macro']\n",
    "    results = pd.DataFrame(\n",
    "        [accuracy, precision_micro, precision_macro, recall_micro, recall_macro, f1_micro, f1_macro],\n",
    "        index=columns\n",
    "    ).T\n",
    "    conf_matrix = pd.DataFrame(\n",
    "        conf_matrix,\n",
    "        columns=['Predicted: 0', 'Predicted: 1', 'Predicted: 2'],\n",
    "        index=['Actual: 0', 'Actual: 1', 'Actual: 2']\n",
    "    )\n",
    "    \n",
    "    return results, conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=2)\n",
    "dt.fit(X_train, y_train)\n",
    "dt_res, dt_conf = get_scores(dt)\n",
    "dt_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=1)\n",
    "lr.fit(X_train, y_train)\n",
    "lr_res, lr_conf = get_scores(lr)\n",
    "lr_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторые классификаторы (например, логистическая регрессия, решающее дерево) могут быть использованы не только для задач бинарной классификации, но и для задач многоклассовой классификации. В общем же случае для решения задачи многоклассовой классификации можно свести ее к задачам бинарной разными методами.\n",
    "\n",
    "#### One-vs-All\n",
    "\n",
    "Разбиваем задачу многоклассовой классификации с $K$ классами на $K$ задач бинарной классификации, где обучаем классификаторы, которые предсказывают ответы вида \"принадлежит классу $k$ / не принадлежит классу $k$\".\n",
    "\n",
    "k-я задача:\n",
    "\n",
    "- $X = \\left(x_i, [y_i = k] - [y_i \\neq k]\\right)_{i=1}^\\ell$\n",
    "\n",
    "- классификатор $a_k(x) = \\operatorname{sign}\\langle w_k, x\\rangle$\n",
    "\n",
    "В качестве предсказания выбираем класс, соответствующий наиболее \"уверенному\" в своем классе классификатору:\n",
    "\n",
    "$$\n",
    "a(x) = \\arg\\max_{k\\in\\{1, \\ldots, K\\}}\\langle w_k, x\\rangle\n",
    "$$\n",
    "\n",
    "#### One-vs-One\n",
    "\n",
    "Разбиваем задачу многоклассовой классификации с $K$ классами на $\\frac{K(K - 1)}{2}$ задач бинарной классификации, где для каждой пары классов $(k, k')$ обучаем классификатор, который предсказывает ответы вида \"принадлежит классу $k$ / принадлежит классу $k'$\".\n",
    "\n",
    "Задача для $(k, k')$:\n",
    "\n",
    "- $X = \\left(x_i, [y_i = k] - [y_i \\neq k']\\right)_{i=1}^\\ell$\n",
    "\n",
    "- классификатор $a_{k, k'}(x) = \\operatorname{sign}\\langle w_{k, k'}, x\\rangle$\n",
    "\n",
    "В качестве предсказания выбираем класс, который чаще всего выбирался бинарными классификаторами:\n",
    "\n",
    "$$\n",
    "a(x) = \\arg\\max_{k\\in\\{1, \\ldots, K\\}}\\left|\\{k':a_{k, k'}(x) = 1\\}\\right|\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovr = OneVsRestClassifier(lr)\n",
    "ovr.fit(X_train, y_train)\n",
    "ovr_res, ovr_conf = get_scores(ovr)\n",
    "ovr_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovr_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovr.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovo = OneVsOneClassifier(lr)\n",
    "ovo.fit(X_train, y_train)\n",
    "ovo_res, ovo_conf = get_scores(ovo)\n",
    "ovo_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovo_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovo.estimators_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
