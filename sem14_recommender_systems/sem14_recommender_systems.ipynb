{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Materials from:** https://nbviewer.jupyter.org/url/courses.cit.cornell.edu/info2950_2014fa/resources/lec22.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This follows chpt2 of \"Programming Collective Intelligence\", by T. Segaran:\n",
    "(\"Ask your friends, weight according to similarity...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A dictionary of movie reviewers and their ratings of a small set of movies\n",
    "reviews={\n",
    "    'Lisa Rose':\n",
    "        {'Lady in the Water': 2.5, 'Snakes on a Plane': 3.5, 'Just My Luck': 3.0,\n",
    "         'Superman Returns': 3.5, 'You, Me and Dupree': 2.5, 'The Night Listener': 3.0},\n",
    "    'Gene Seymour':\n",
    "        {'Lady in the Water': 3.0, 'Snakes on a Plane': 3.5, 'Just My Luck': 1.5,\n",
    "         'Superman Returns': 5.0, 'The Night Listener': 3.0, 'You, Me and Dupree': 3.5}, \n",
    "    'Michael Phillips':\n",
    "        {'Lady in the Water': 2.5, 'Snakes on a Plane': 3.0,\n",
    "         'Superman Returns': 3.5, 'The Night Listener': 4.0},\n",
    "    'Claudia Puig':\n",
    "        {'Snakes on a Plane': 3.5, 'Just My Luck': 3.0, 'The Night Listener': 4.5,\n",
    "         'Superman Returns': 4.0, 'You, Me and Dupree': 2.5},\n",
    "    'Mick LaSalle':\n",
    "         {'Lady in the Water': 3.0, 'Snakes on a Plane': 4.0, 'Just My Luck': 2.0,\n",
    "          'Superman Returns': 3.0, 'The Night Listener': 3.0, 'You, Me and Dupree': 2.0}, \n",
    "    'Jack Matthews':\n",
    "        {'Lady in the Water': 3.0, 'Snakes on a Plane': 4.0,\n",
    "         'The Night Listener': 3.0, 'Superman Returns': 5.0, 'You, Me and Dupree': 3.5},\n",
    "    'Toby':\n",
    "        {'Snakes on a Plane':4.5,'You, Me and Dupree':1.0,'Superman Returns':4.0}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reviews), list(map(len,reviews.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what has Toby reviewed:\n",
    "reviews['Toby']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the critics who reviewed these two:\n",
    "dupree='You, Me and Dupree'\n",
    "snakes='Snakes on a Plane'\n",
    "\n",
    "crit2 = [critic for critic in reviews if dupree in reviews[critic] and snakes in reviews[critic]]\n",
    "du_ratings = [reviews[c][dupree] for c in crit2]\n",
    "sn_ratings = [reviews[c][snakes] for c in crit2]\n",
    "\n",
    "plt.figure(figsize=(4.5,4.5))\n",
    "plt.xlim(.9,5.1),\n",
    "plt.ylim(.9,5.1)\n",
    "plt.xlabel(dupree)\n",
    "plt.ylabel(snakes)\n",
    "\n",
    "plt.plot(du_ratings,sn_ratings,'bo')\n",
    "\n",
    "for crit,x,y in zip(crit2,du_ratings,sn_ratings):\n",
    "    print('{}: ({},{})'.format(crit,x,y))\n",
    "#move Puig down to avoid collision\n",
    "    plt.text(x+.05,y+(.01 if 'Puig' not in crit else -.2),crit.split()[-1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Who's close to whom in the above fig?\n",
    "Based on just these two movies, we'd conclude that Rose and Puig are quite close (exact agreement), whereas Toby is quite different from Seymour, differing by 2.5 on one movie and 1 on the other.\n",
    "The distance between them on the plot above is $\\sqrt{(3.5-1)^2+(4.5-3.5)^2}\\approx2.69$. For critics who have co-rated multiple movies, this notion of distance generalizes to taking the square root of the sum of the squares of all of those co-rated movies, $d^2_{ij}=\\sum_m\\bigl(r_m(i) - r_m(j)\\bigr)^2$. (This corresponds to the Euclidean distance between $r_m(i)$ and $r_m(j)$, considered as vectors in an M-dimensional space, $d^2_{ij}=\\bigl(\\vec r(i)-\\vec r(j)\\bigr)^2$.)\n",
    "\n",
    "It is convenient to employ a measure of *similarity* rather than of distance (the two are inversely related), defined as $s_{ij}={1\\over 1+d_{ij}^2}$. The similarity $s_{ij}$ goes from 0 similarity when the distance is very large, up to similarity 1 when the distance goes to zero.  Here `sim_distance()` returns this similarity score for two reviewers, based only on the items they've both rated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sim_distance(prefs,person1,person2):\n",
    "  # Get the list of shared_items\n",
    "    shared_items = [item for item in prefs[person1] if item in prefs[person2]]\n",
    "\n",
    "  # if they have no ratings in common, return 0\n",
    "    if len(shared_items) == 0:\n",
    "        return 0\n",
    "\n",
    "    v1 = np.array([prefs[person1][item] for item in shared_items])\n",
    "    v2 = np.array([prefs[person2][item] for item in shared_items])\n",
    "\n",
    "  # use numpy euclidean distance (sqrt(sum of squares))\n",
    "    dist = np.linalg.norm(v1 - v2)\n",
    "\n",
    "  #transform to similarity ranging from 0 to 1\n",
    "  #truncate to three after decimal point\n",
    "    return 1/(1 + dist**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'Lisa Rose' happened to rate all movies\n",
    "all_movies = sorted(reviews['Lisa Rose'],key=reviews['Lisa Rose'].get)\n",
    "\n",
    "def ratings(critic):\n",
    "    return np.array([reviews[critic][m] for m in all_movies])\n",
    "\n",
    "for crit in ('Lisa Rose','Gene Seymour','Mick LaSalle'):\n",
    "    print(crit, ratings(crit))\n",
    "    plt.plot(ratings(crit),'o-',label=crit)\n",
    "\n",
    "plt.ylim(0,6)\n",
    "plt.xlim(-.5,5.5)\n",
    "plt.xticks(ticks=range(0, 6), labels=all_movies, rotation=45)\n",
    "plt.xlabel('movie')\n",
    "plt.ylabel('rating')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take two example critics\n",
    "round(sim_distance(reviews,'Lisa Rose','Gene Seymour'),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a different distance measure: Pearson correlation coefficient (+1 if correlated, -1 if anticorrelated, and values in between for noisy correlation)\n",
    "\n",
    "Recall from [power_law.ipynb](http://nbviewer.ipython.org/url/courses.cit.cornell.edu/info2950_2013fa/resources/powerlaw.ipynb)\n",
    "that `stats.linregress()` also returned an `r_value`, known as the\n",
    "\"[Pearson correlation coefficient](http://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient)\",\n",
    "defined as\n",
    "\n",
    "$$\\qquad {E[(X-E[X])(Y-E[Y])]\\over \\sigma_X\\sigma_Y}$$\n",
    "\n",
    "Note that Pearson corrects for \"grade inflation\", unlike euclidean distance: one can be systematically higher than the other, offset won't matter. The numerator is the \"covariance\" of X and Y, equal to a times the variance of X when Y=aX+b. The denominator is equal to the absolute value |a| times the variance when Y=aX+b, so the value of the Pearson correlation coefficient is $\\pm1$ for an exact linear relation (where the sign depends on the sign of the slope a). For noisier data the value is between -1 and 1, with 0 corresponding to no correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('Pearson.png',width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#three critics who rated all 6\n",
    "crit6 = [crit for crit in reviews if len(reviews[crit])==6]\n",
    "#three pairs from above set\n",
    "pairs = [(crit6[i],crit6[j]) for i in range(len(crit6)) for j in range(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare the similarity based on distance with Pearson for these three pairs:\n",
    "\n",
    "_, ax = plt.subplots(2, 3, figsize=(12, 8))\n",
    "for j,(c1,c2) in enumerate(pairs):\n",
    "    ax1 = ax[0][j]\n",
    "    ax1.scatter(ratings(c1),ratings(c2))\n",
    "    for (x,y) in zip(ratings(c1),ratings(c2)):\n",
    "        ax1.plot((x,x),(x,y),'r-',marker='_',ms=10)        \n",
    "    ax1.grid(True)\n",
    "    ax1.set_xticks(range(1,6))\n",
    "    ax1.set_yticks(range(1,6))\n",
    "    ax1.axis((0.9,5.1,0.9,5.1))\n",
    "    ax1.set_xlabel(c1)\n",
    "    ax1.set_ylabel(c2)\n",
    "    ax1.plot((1,5),(1,5),'b--')\n",
    "    d = np.linalg.norm(ratings(c1) - ratings(c2))\n",
    "    ax1.text(1,4.25,'sim_distance={:.2f}\\n(distance={:.2f})'.\\\n",
    "         format(sim_distance(reviews,c1,c2),d),fontsize=12,color='b')\n",
    "        \n",
    "    ax2 = ax[1][j]\n",
    "    ax2.scatter(ratings(c1),ratings(c2))\n",
    "    ax2.set_xticks(range(1,6))\n",
    "    ax2.set_yticks(range(1,6))\n",
    "    ax2.axis((0.9,5.1,0.9,5.1))\n",
    "    ax2.set_xlabel(c1)\n",
    "    ax2.set_ylabel(c2)\n",
    "    r,p = stats.pearsonr(ratings(c1),ratings(c2))\n",
    "    ax2.text(1,4.25,'Pearson r={:.2f}\\n(p={:.2f})'.format(r,p),fontsize=12,color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define function to look at the Pearson r for a few critic pairs\n",
    "\n",
    "def show_pearson(prefs,crit1,crit2):\n",
    "    shared_items=[item for item in prefs[crit1] if item in prefs[crit2]]\n",
    "\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.xlim(.8,5.2)\n",
    "    plt.ylim(.8,5.2)\n",
    "    xdata = [prefs[crit1][item] for item in shared_items]\n",
    "    ydata = [prefs[crit2][item] for item in shared_items]\n",
    "\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(xdata,ydata)\n",
    "    plt.xlabel(crit1)\n",
    "    plt.ylabel(crit2)\n",
    "    \n",
    "    plt.plot(xdata,ydata,'o')\n",
    "    plt.plot(slope*np.arange(6)+intercept,'--')\n",
    "    \n",
    "    voffset={(x,y):.01 for x,y in zip(xdata,ydata)}\n",
    "    for item in shared_items:\n",
    "        x,y=prefs[crit1][item],prefs[crit2][item]\n",
    "        plt.text(x+.05, y+voffset[(x,y)], item)\n",
    "        voffset[(x,y)]-=.15\n",
    "    plt.text(1.25,4.5,'Pearson r = {:.2f}'.format(r_value),fontsize=14,color='b')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#two fake critics roughly correlated\n",
    "fcritics={'critic1':{'Dupree':1,'Night':2.5,'Lady':3,'Snakes':3.5,'Superman':4.5},\n",
    "         'critic2':{'Dupree':2,'Night':3,'Lady':2.5,'Snakes':3.5,'Superman':3.5}}\n",
    "show_pearson(fcritics,'critic1','critic2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#two from original set not quite as well correlated\n",
    "show_pearson(reviews,'Mick LaSalle','Gene Seymour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now define similarity measure, analogous to sim_distance\n",
    "def sim_pearson(prefs,crit1,crit2):\n",
    "    shared_items=[item for item in prefs[crit1] if item in prefs[crit2]]\n",
    "  #  shared_items=list(set(prefs[person1]) & set(prefs[person2]))  #equivalent\n",
    "    if len(shared_items)==0:\n",
    "        return 0\n",
    "    xdata = [prefs[crit1][item] for item in shared_items]\n",
    "    ydata = [prefs[crit2][item] for item in shared_items]\n",
    "    r,p = stats.pearsonr(xdata,ydata)\n",
    "    # check for nan\n",
    "    if r != r:\n",
    "        return 0\n",
    "    else:\n",
    "        return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now rank the critics, find `other` critics similar to given `person` ranked according to similarity measure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns the best matches for person from the prefs dictionary. \n",
    "# Number of results and similarity function are optional params.\n",
    "\n",
    "def topMatches(prefs, person, n=5, similarity=sim_pearson):\n",
    "    scores=[(other, round(similarity(prefs,person,other),3))\n",
    "                      for other in prefs if other != person]\n",
    "    return sorted(scores,key=lambda x:x[1],reverse=True)[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topMatches(reviews,'Toby',6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how topmatches function works using other similarity measure\n",
    "topMatches(reviews,'Toby', n=3, similarity=sim_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But here what we really want is to make a recommendation. For this, we could use just the most similar person, and select any movies that person liked that you haven't seen. But that person might not have seen the most relevant movie, or might be an outlier on that particular movie (i.e., liked it but most people with tastes similar to yours didn't like it, or vice versa).\n",
    "\n",
    "So instead, get recommendations by using a weighted average of *every* other person's ratings, weighted according to that person's similarity to you. Suppose person $i$ has similarity $s_i$ to you, and gives rating $r_i(m)$ to movie $m$ that you haven't seen, then that person will contribute $s_i\\cdot r_i(m)$ to your likely preference for movie $m$, so that others' ratings are weighted in proportion to their similarity to you. Then we sum on $i$ over all those who have rated movie $m$, and divide by the same sum over the $s_i$ to give the expected value of your rating of movie $m$:\n",
    "\n",
    "$$\\qquad\\qquad E[r_m]={\\sum_{i\\ |\\ i\\ {\\rm rated\\ }m} s_i\\cdot r_m(i)\\over \\sum_{i\\ |\\ i\\ {\\rm rated\\ }m} s_i}$$\n",
    "\n",
    "This equation is implemented in the function below, and gives the expected rating of all movies one hasn't seen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRecommendations(prefs,person,similarity=sim_pearson):\n",
    "    totals={}\n",
    "    simSums={}\n",
    "    for other in prefs:\n",
    "        # don't compare me to myself\n",
    "        if other==person:\n",
    "            continue\n",
    "        sim = similarity(prefs,person,other)\n",
    "    \n",
    "        # ignore scores of zero or lower\n",
    "        if sim <= 0:\n",
    "            continue\n",
    "        for item in prefs[other]:\n",
    "            # only score movies I haven't seen yet\n",
    "            if item not in prefs[person] or prefs[person][item] == 0:\n",
    "                # Similarity * Score\n",
    "                if item not in totals:\n",
    "                    totals[item]=0\n",
    "                    simSums[item]=0\n",
    "                totals[item] += prefs[other][item]*sim\n",
    "                # Sum of similarities\n",
    "                simSums[item] += sim\n",
    "\n",
    "    # Create the normalized list\n",
    "    rankings =[(item,round((totals[item] + 1e-15)/(simSums[item] + 1e-15),3)) for item in totals]\n",
    "\n",
    "    # Return the sorted list\n",
    "    return sorted(rankings,key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getRecommendations(reviews,'Toby')\n",
    "#also gives likely rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#or use other distance measure\n",
    "getRecommendations(reviews,'Toby',similarity=sim_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose you want matching products, e.g., Amazon \"customers have also bought\". Now instead of similarity between people based on the ratings given to some object, averaged over objects both have rated, now we consider similarity between objects that are rated, based on whether different reviewers tend to rate them similarly.  This is equivalent to reversing the roles of reviewers and objects, so that it is now the objects that are rating the reviewers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#first reverse role of items and objects\n",
    "def transformPrefs(prefs):\n",
    "    result=defaultdict(dict)\n",
    "    for person in prefs:\n",
    "        for item in prefs[person]:      \n",
    "          # Flip item and person\n",
    "          result[item][person]=prefs[person][item]\n",
    "    return dict(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try this for the movie ratings above, to get similarities between movies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies=transformPrefs(reviews)\n",
    "dict(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now topmatches gives similar movies rather than similar reviewers\n",
    "topMatches(movies,'Superman Returns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note negative scores, reviewers who like one dislike the other\n",
    "show_pearson(movies,'Just My Luck','Superman Returns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the analog of the recommended movie for a given person, after reversing the roles of people and movies, is the recommended person for a movie, i.e., the one most likely to like it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getRecommendations(movies,'Just My Luck')\n",
    "#find critics for movie ... invite to premiere?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's easy to apply these to de.licio.us data (details in the chpt2 of text mentioned at top).\n",
    "python code to interact with delicious api is here:\n",
    "http://code.google.com/p/pydelicious/source\n",
    "\n",
    "Also works with real movie datasets from movielens, http://www.grouplens.org/datasets/movielens/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigger data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_ratings = pd.read_csv('data/ratings.csv')\n",
    "df_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_reviews = {}\n",
    "for user_id in df_ratings['userId'].unique().astype(int):\n",
    "    users_reviews[user_id] = {}\n",
    "    for row in df_ratings[df_ratings['userId'] == user_id].iterrows():\n",
    "        movie_id = int(row[1]['movieId'])\n",
    "        rating = row[1]['rating']\n",
    "        users_reviews[user_id][movie_id] = rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies = pd.read_csv('data/movies.csv')\n",
    "df_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id2name(movie_id):\n",
    "    return df_movies[df_movies['movieId'] == movie_id]['title'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_cnt = df_ratings['movieId'].value_counts()\n",
    "\n",
    "def user_rated_movies(user_id, min_cnt=10):\n",
    "    return {id2name(movie_id): rating for movie_id, rating in users_reviews[user_id].items() if movies_cnt[movie_id] >= min_cnt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(user_rated_movies(599).items(), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getRecommendations(prefs, person, similarity=sim_pearson, min_cnt=10):\n",
    "    totals = {}\n",
    "    simSums = {}\n",
    "    moviesCnt = {}\n",
    "    for other in prefs:\n",
    "        # don't compare me to myself\n",
    "        if other==person:\n",
    "            continue\n",
    "        sim = similarity(prefs,person,other)\n",
    "    \n",
    "        # ignore scores of zero or lower\n",
    "        if sim <= 0:\n",
    "            continue\n",
    "        for item in prefs[other]:\n",
    "            # only score movies I haven't seen yet\n",
    "            if item not in prefs[person] or prefs[person][item] == 0:\n",
    "                # Similarity * Score\n",
    "                if item not in totals:\n",
    "                    totals[item] = 0\n",
    "                    simSums[item] = 0\n",
    "                    moviesCnt[item] = 0\n",
    "                totals[item] += prefs[other][item]*sim\n",
    "                # Sum of similarities\n",
    "                simSums[item] += sim\n",
    "                moviesCnt[item] += 1\n",
    "\n",
    "    # Create the normalized list\n",
    "    rankings = [(item,(totals[item] + 1e-15)/(simSums[item] + 1e-15)) for item in totals if moviesCnt[item] >= min_cnt]\n",
    "\n",
    "    # Return the sorted list\n",
    "    return sorted(rankings,key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMoviesRecommendations(user_id, similarity=sim_pearson, min_cnt=10):\n",
    "    return name_keys({k: v for (k, v) in getRecommendations(users_reviews, user_id, similarity, min_cnt)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getMoviesRecommendations(599)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def topRecommendations(user_id, similarity=sim_pearson, min_cnt=20, n=10):\n",
    "    scores = getMoviesRecommendations(user_id, similarity, min_cnt)\n",
    "    return sorted(scores.items(), key=lambda x:x[1], reverse=True)[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topRecommendations(599)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topRecommendations(599, sim_distance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
